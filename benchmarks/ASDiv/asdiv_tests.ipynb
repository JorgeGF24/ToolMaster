{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/ASDiv to /homes/jg2619/.cache/huggingface/datasets/text/ASDiv-a373d3734b174a1b/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1673.04it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 97.86it/s]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /homes/jg2619/.cache/huggingface/datasets/text/ASDiv-a373d3734b174a1b/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 238\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "load_dataset(\"/vol/bitbucket/jg2619/augmenting_llms/benchmarks/ASDiv/\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/jg2619/toolformer-luci/oldtoolvenv/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<problem grade=\"1\" id=\"nluds-0001\" source=\"http://www.k5learning.com\">\n",
      "\t\tSeven red apples and two green apples are in the basket.\n",
      "\t\t<question>How many apples are in the basket?</question>\n",
      "<solution-type>Addition</solution-type>\n",
      "<answer>9 (apples)</answer>\n",
      "<formula>7+2=9</formula>\n",
      "</problem>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "# Reading the data inside the xml\n",
    "# file to a variable under the name\n",
    "# data\n",
    "with open('ASDiv.xml', 'r') as f:\n",
    "    data = f.read()\n",
    " \n",
    "# Passing the stored data inside\n",
    "# the beautifulsoup parser, storing\n",
    "# the returned object\n",
    "Bs_data = BeautifulSoup(data, \"lxml\")\n",
    "\n",
    "\n",
    "# Finding all instances of tag\n",
    "# `unique`\n",
    "b_unique = Bs_data.find_all('problem')\n",
    " \n",
    "#print(b_unique)\n",
    " \n",
    "# Using find() to extract attributes\n",
    "# of the first instance of the tag\n",
    "b_name = Bs_data.find('problem', {'id':'nluds-0001'})\n",
    " \n",
    "print(b_name)\n",
    " \n",
    "# Extracting the data stored in a\n",
    "# specific attribute of the\n",
    "# `child` tag\n",
    "value = b_name.get('test')\n",
    " \n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1351433/4071319210.py:19: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  questions.append(str(problem.find(text=True, recursive=False)[3:-3] + \" \" + problem.question.text))\n"
     ]
    }
   ],
   "source": [
    "problem_ids = []\n",
    "# Read problem ids from /vol/bitbucket/jg2619/augmenting_llms/benchmarks/ASDiv/fold0.txt file, which has lines such as:\n",
    "# nluds-0153\n",
    "# nluds-2291\n",
    "# etc\n",
    "\n",
    "import re\n",
    "\n",
    "with open('/vol/bitbucket/jg2619/augmenting_llms/benchmarks/ASDiv/fold0.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        problem_ids.append(line.strip())\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for id in problem_ids:\n",
    "    problem = Bs_data.find(\"problem\", id=id)\n",
    "    questions.append(str(problem.find(text=True, recursive=False)[3:-3] + \" \" + problem.question.text))\n",
    "    answers.append(re.sub('[^0-9.]', '', problem.answer.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strips string of all non-numeric or fullstop characters:\n",
    "def strip_non_numeric(string):\n",
    "    return re.sub('[^0-9.]', '', string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '76',\n",
       " '3',\n",
       " '3',\n",
       " '9',\n",
       " '65',\n",
       " '10',\n",
       " '2',\n",
       " '12',\n",
       " '28',\n",
       " '7',\n",
       " '45',\n",
       " '9',\n",
       " '3',\n",
       " '60',\n",
       " '6',\n",
       " '6',\n",
       " '77',\n",
       " '4',\n",
       " '155',\n",
       " '20',\n",
       " '48',\n",
       " '7',\n",
       " '6',\n",
       " '5',\n",
       " '8',\n",
       " '9',\n",
       " '5',\n",
       " '8',\n",
       " '23',\n",
       " '16',\n",
       " '19',\n",
       " '45',\n",
       " '127',\n",
       " '34',\n",
       " '43',\n",
       " '16',\n",
       " '275',\n",
       " '39',\n",
       " '18',\n",
       " '9',\n",
       " '9',\n",
       " '15',\n",
       " '10',\n",
       " '16',\n",
       " '11760',\n",
       " '6',\n",
       " '83',\n",
       " '14',\n",
       " '93',\n",
       " '11',\n",
       " '13',\n",
       " '8',\n",
       " '98',\n",
       " '18',\n",
       " '87',\n",
       " '11',\n",
       " '44',\n",
       " '19',\n",
       " '30',\n",
       " '45',\n",
       " '7',\n",
       " '8',\n",
       " '10',\n",
       " '6',\n",
       " '12',\n",
       " '5',\n",
       " '100',\n",
       " '3',\n",
       " '39',\n",
       " '38',\n",
       " '9',\n",
       " '18',\n",
       " '44',\n",
       " '11',\n",
       " '60',\n",
       " '7',\n",
       " '42',\n",
       " '18',\n",
       " '94',\n",
       " '28',\n",
       " '9',\n",
       " '22',\n",
       " '17',\n",
       " '38',\n",
       " '7',\n",
       " '929',\n",
       " '11',\n",
       " '62',\n",
       " '6',\n",
       " '46',\n",
       " '5',\n",
       " '55',\n",
       " '55',\n",
       " '12',\n",
       " '17',\n",
       " '37',\n",
       " '15',\n",
       " '61',\n",
       " '40',\n",
       " '149',\n",
       " '18',\n",
       " '85',\n",
       " '78',\n",
       " '40',\n",
       " '5',\n",
       " '54',\n",
       " '240',\n",
       " '7',\n",
       " '120',\n",
       " '30',\n",
       " '180',\n",
       " '2',\n",
       " '164',\n",
       " '39',\n",
       " '109',\n",
       " '3',\n",
       " '82',\n",
       " '64',\n",
       " '98',\n",
       " '6',\n",
       " '385',\n",
       " '12',\n",
       " '25',\n",
       " '22',\n",
       " '48',\n",
       " '5',\n",
       " '45',\n",
       " '4',\n",
       " '182',\n",
       " '35',\n",
       " '174',\n",
       " '117',\n",
       " '22',\n",
       " '4',\n",
       " '12',\n",
       " '24',\n",
       " '12',\n",
       " '2',\n",
       " '9',\n",
       " '7',\n",
       " '6',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " '8',\n",
       " '12',\n",
       " '8',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '25',\n",
       " '3',\n",
       " '11',\n",
       " '1',\n",
       " '78',\n",
       " '1',\n",
       " '31',\n",
       " '12',\n",
       " '65',\n",
       " '7',\n",
       " '4',\n",
       " '6',\n",
       " '5',\n",
       " '4',\n",
       " '11',\n",
       " '6',\n",
       " '11',\n",
       " '7',\n",
       " '7',\n",
       " '7',\n",
       " '13',\n",
       " '7',\n",
       " '37',\n",
       " '5',\n",
       " '18',\n",
       " '79',\n",
       " '34',\n",
       " '31',\n",
       " '59',\n",
       " '14',\n",
       " '67',\n",
       " '9',\n",
       " '49',\n",
       " '6',\n",
       " '6',\n",
       " '23',\n",
       " '6',\n",
       " '17',\n",
       " '2',\n",
       " '32',\n",
       " '2',\n",
       " '22',\n",
       " '9',\n",
       " '42',\n",
       " '9',\n",
       " '6',\n",
       " '16',\n",
       " '9',\n",
       " '48',\n",
       " '24',\n",
       " '300',\n",
       " '28',\n",
       " '21',\n",
       " '432',\n",
       " '20',\n",
       " '18',\n",
       " '15',\n",
       " '72',\n",
       " '12',\n",
       " '2250',\n",
       " '12',\n",
       " '486',\n",
       " '45',\n",
       " '24',\n",
       " '40',\n",
       " '21',\n",
       " '54',\n",
       " '3285',\n",
       " '56',\n",
       " '6003',\n",
       " '12',\n",
       " '20',\n",
       " '20',\n",
       " '2205',\n",
       " '30',\n",
       " '372',\n",
       " '72',\n",
       " '1035',\n",
       " '14.57',\n",
       " '15',\n",
       " '8',\n",
       " '64',\n",
       " '7',\n",
       " '10',\n",
       " '8',\n",
       " '11',\n",
       " '48']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sasha and Julie are best friends playing on opposing basketball teams. The teams have two practice games scheduled. In the first game, Sasha had the home court advantage and scored 14 points. Julie scored 4 fewer points than Sasha in the same game. Sasha always struggles during away games and their second match was at Julie's home court. Sasha scored 6 fewer points in the second game than Julie's score in the first game. How many total points did Sasha score during both games?\n",
      "\n",
      "42489\n",
      "\n",
      "\n",
      "Step by step reasoning: The first game was at Sasha's home court, and the second game was at Julie's home court. Therefore, Sasha's score in the first game was [Calculator(\n",
      "\n",
      "According to its nutritional info, a bag of chips has 250 calories per serving. If a 300g bag has 5 servings, how many grams can you eat if your daily calorie target is 2000 and you have already consumed 1800 calories?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'skip_special_tokens': 'list' object cannot be converted to 'PyBool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 50\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode([ \u001b[39m4821\u001b[39m,   \u001b[39m284\u001b[39m,   \u001b[39m663\u001b[39m, \u001b[39m24000\u001b[39m,  \u001b[39m7508\u001b[39m,    \u001b[39m11\u001b[39m,   \u001b[39m257\u001b[39m,  \u001b[39m6131\u001b[39m,   \u001b[39m286\u001b[39m, \u001b[39m12014\u001b[39m,\n\u001b[1;32m     45\u001b[0m           \u001b[39m468\u001b[39m,  \u001b[39m8646\u001b[39m, \u001b[39m14653\u001b[39m,   \u001b[39m583\u001b[39m,  \u001b[39m7351\u001b[39m,    \u001b[39m13\u001b[39m,  \u001b[39m1002\u001b[39m,   \u001b[39m257\u001b[39m,  \u001b[39m5867\u001b[39m,    \u001b[39m70\u001b[39m,\n\u001b[1;32m     46\u001b[0m          \u001b[39m6131\u001b[39m,   \u001b[39m468\u001b[39m,   \u001b[39m642\u001b[39m, \u001b[39m43096\u001b[39m,    \u001b[39m11\u001b[39m,   \u001b[39m703\u001b[39m,   \u001b[39m867\u001b[39m, \u001b[39m16379\u001b[39m,   \u001b[39m460\u001b[39m,   \u001b[39m345\u001b[39m,\n\u001b[1;32m     47\u001b[0m          \u001b[39m4483\u001b[39m,   \u001b[39m611\u001b[39m,   \u001b[39m534\u001b[39m,  \u001b[39m4445\u001b[39m, \u001b[39m28740\u001b[39m,  \u001b[39m2496\u001b[39m,   \u001b[39m318\u001b[39m,  \u001b[39m4751\u001b[39m,   \u001b[39m290\u001b[39m,   \u001b[39m345\u001b[39m,\n\u001b[1;32m     48\u001b[0m           \u001b[39m423\u001b[39m,  \u001b[39m1541\u001b[39m, \u001b[39m13529\u001b[39m, \u001b[39m21431\u001b[39m, \u001b[39m14653\u001b[39m,    \u001b[39m30\u001b[39m]))\n\u001b[0;32m---> 50\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39;49mdecode([  \u001b[39m198\u001b[39;49m,   \u001b[39m198\u001b[39;49m,  \u001b[39m8600\u001b[39;49m,   \u001b[39m416\u001b[39;49m,  \u001b[39m2239\u001b[39;49m, \u001b[39m14607\u001b[39;49m,    \u001b[39m25\u001b[39;49m,   \u001b[39m383\u001b[39;49m,   \u001b[39m717\u001b[39;49m,   \u001b[39m983\u001b[39;49m,\n\u001b[1;32m     51\u001b[0m           \u001b[39m373\u001b[39;49m,   \u001b[39m379\u001b[39;49m, \u001b[39m32151\u001b[39;49m,   \u001b[39m338\u001b[39;49m,  \u001b[39m1363\u001b[39;49m,  \u001b[39m2184\u001b[39;49m,    \u001b[39m11\u001b[39;49m,   \u001b[39m290\u001b[39;49m,   \u001b[39m262\u001b[39;49m,  \u001b[39m1218\u001b[39;49m,\n\u001b[1;32m     52\u001b[0m           \u001b[39m983\u001b[39;49m,   \u001b[39m373\u001b[39;49m,   \u001b[39m379\u001b[39;49m, \u001b[39m21946\u001b[39;49m,   \u001b[39m338\u001b[39;49m,  \u001b[39m1363\u001b[39;49m,  \u001b[39m2184\u001b[39;49m,    \u001b[39m13\u001b[39;49m,  \u001b[39m8447\u001b[39;49m,    \u001b[39m11\u001b[39;49m,\n\u001b[1;32m     53\u001b[0m         \u001b[39m32151\u001b[39;49m,   \u001b[39m338\u001b[39;49m,  \u001b[39m4776\u001b[39;49m,   \u001b[39m287\u001b[39;49m,   \u001b[39m262\u001b[39;49m,   \u001b[39m717\u001b[39;49m,   \u001b[39m983\u001b[39;49m,   \u001b[39m373\u001b[39;49m,   \u001b[39m685\u001b[39;49m,  \u001b[39m9771\u001b[39;49m,\n\u001b[1;32m     54\u001b[0m          \u001b[39m3129\u001b[39;49m,  \u001b[39m1352\u001b[39;49m,     \u001b[39m7\u001b[39;49m],[  \u001b[39m198\u001b[39;49m,   \u001b[39m198\u001b[39;49m,  \u001b[39m8600\u001b[39;49m,   \u001b[39m416\u001b[39;49m,  \u001b[39m2239\u001b[39;49m, \u001b[39m14607\u001b[39;49m,    \u001b[39m25\u001b[39;49m,   \u001b[39m317\u001b[39;49m,  \u001b[39m6131\u001b[39;49m,   \u001b[39m286\u001b[39;49m,\n\u001b[1;32m     55\u001b[0m         \u001b[39m12014\u001b[39;49m,   \u001b[39m468\u001b[39;49m,  \u001b[39m8646\u001b[39;49m, \u001b[39m14653\u001b[39;49m,   \u001b[39m583\u001b[39;49m,  \u001b[39m7351\u001b[39;49m,    \u001b[39m13\u001b[39;49m,  \u001b[39m8447\u001b[39;49m,    \u001b[39m11\u001b[39;49m,   \u001b[39m611\u001b[39;49m,\n\u001b[1;32m     56\u001b[0m           \u001b[39m345\u001b[39;49m,   \u001b[39m460\u001b[39;49m,  \u001b[39m4483\u001b[39;49m,   \u001b[39m642\u001b[39;49m, \u001b[39m11668\u001b[39;49m,    \u001b[39m11\u001b[39;49m,   \u001b[39m340\u001b[39;49m,   \u001b[39m468\u001b[39;49m,   \u001b[39m685\u001b[39;49m,  \u001b[39m9771\u001b[39;49m,\n\u001b[1;32m     57\u001b[0m          \u001b[39m3129\u001b[39;49m,  \u001b[39m1352\u001b[39;49m,     \u001b[39m7\u001b[39;49m]))\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode([ \u001b[39m2953\u001b[39m, \u001b[39m31908\u001b[39m,   \u001b[39m338\u001b[39m,  \u001b[39m2156\u001b[39m,    \u001b[39m11\u001b[39m,   \u001b[39m612\u001b[39m,   \u001b[39m318\u001b[39m,  \u001b[39m5403\u001b[39m,   \u001b[39m355\u001b[39m,   \u001b[39m881\u001b[39m,\n\u001b[1;32m     63\u001b[0m         \u001b[39m11676\u001b[39m,   \u001b[39m355\u001b[39m,  \u001b[39m6463\u001b[39m,  \u001b[39m8506\u001b[39m,    \u001b[39m13\u001b[39m,   \u001b[39m679\u001b[39m,   \u001b[39m468\u001b[39m,   \u001b[39m257\u001b[39m,  \u001b[39m2472\u001b[39m,   \u001b[39m286\u001b[39m,\n\u001b[1;32m     64\u001b[0m          \u001b[39m2319\u001b[39m,  \u001b[39m6463\u001b[39m,  \u001b[39m8506\u001b[39m,   \u001b[39m287\u001b[39m,   \u001b[39m465\u001b[39m,  \u001b[39m2156\u001b[39m,    \u001b[39m13\u001b[39m, \u001b[39m31908\u001b[39m,  \u001b[39m5839\u001b[39m,  \u001b[39m3126\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m          \u001b[39m5929\u001b[39m,  \u001b[39m2472\u001b[39m,   \u001b[39m286\u001b[39m,   \u001b[39m262\u001b[39m,  \u001b[39m1271\u001b[39m,   \u001b[39m286\u001b[39m,  \u001b[39m1162\u001b[39m,  \u001b[39m5907\u001b[39m,   \u001b[39m290\u001b[39m,  \u001b[39m6463\u001b[39m,\n\u001b[1;32m     68\u001b[0m          \u001b[39m8506\u001b[39m, \u001b[39m31908\u001b[39m,   \u001b[39m468\u001b[39m,   \u001b[39m287\u001b[39m,   \u001b[39m262\u001b[39m,  \u001b[39m2156\u001b[39m,    \u001b[39m30\u001b[39m]))\n",
      "File \u001b[0;32m/vol/bitbucket/jg2619/toolformer-luci/oldtoolvenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3542\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[39m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3540\u001b[0m token_ids \u001b[39m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode(\n\u001b[1;32m   3543\u001b[0m     token_ids\u001b[39m=\u001b[39;49mtoken_ids,\n\u001b[1;32m   3544\u001b[0m     skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens,\n\u001b[1;32m   3545\u001b[0m     clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m   3546\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3547\u001b[0m )\n",
      "File \u001b[0;32m/vol/bitbucket/jg2619/toolformer-luci/oldtoolvenv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:566\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(token_ids, \u001b[39mint\u001b[39m):\n\u001b[1;32m    565\u001b[0m     token_ids \u001b[39m=\u001b[39m [token_ids]\n\u001b[0;32m--> 566\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mdecode(token_ids, skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens)\n\u001b[1;32m    568\u001b[0m clean_up_tokenization_spaces \u001b[39m=\u001b[39m (\n\u001b[1;32m    569\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m clean_up_tokenization_spaces \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    572\u001b[0m )\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'skip_special_tokens': 'list' object cannot be converted to 'PyBool'"
     ]
    }
   ],
   "source": [
    "# Import GPTJ tokenizer:\n",
    "\n",
    "import torch\n",
    "\n",
    "cache_dir = \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "tokenizer.add_tokens([\"[PAD]\"])\n",
    "tokenizer.pad_token=\"[PAD]\"\n",
    "\n",
    "\n",
    "print(tokenizer.decode([   50, 14715,   290, 21946,   389,  1266,  2460,  2712,   319, 12330,\n",
    "         9669,  3466,    13,   383,  3466,   423,   734,  3357,  1830,  7530,\n",
    "           13,   554,   262,   717,   983,    11, 32151,   550,   262,  1363,\n",
    "         2184,  4621,   290,  7781,  1478,  2173,    13, 21946,  7781,   604,\n",
    "         7380,  2173,   621, 32151,   287,   262,   976,   983,    13, 32151,\n",
    "         1464, 12766,  1141,  1497,  1830,   290,   511,  1218,  2872,   373,\n",
    "          379, 21946,   338,  1363,  2184,    13, 32151,  7781,   718,  7380,\n",
    "         2173,   287,   262,  1218,   983,   621, 21946,   338,  4776,   287,\n",
    "          262,   717,   983,    13,  1374,   867,  2472,  2173,   750, 32151,\n",
    "         4776,  1141,  1111,  1830,    30]))\n",
    "print()\n",
    "\n",
    "print(torch.tensor([15309,    11,  7299,    11,   290,  1215,   417, 18829,    68,   389,\n",
    "         2111,   284,  4929,   606,   477,    11, 14878,   326,   318,    13,\n",
    "          220, 17083,   484,   423,  4978, 42489, 14878,    13,   220,  4422,\n",
    "          468,  4978,   642,   517,   621,  7299,    11,   290,  7299,   468,\n",
    "         4978,  1511,  1342,   621,   604,  1661,   355,   867,   355,  1215,\n",
    "          417, 18829,    68,   468,  4978,    13,  1374,   867, 14878,   468,\n",
    "         7299,  4978,    30]).max().item())\n",
    "\n",
    "print(tokenizer.decode([  198,   198,  8600,   416,  2239, 14607,    25,   383,   717,   983,\n",
    "          373,   379, 32151,   338,  1363,  2184,    11,   290,   262,  1218,\n",
    "          983,   373,   379, 21946,   338,  1363,  2184,    13,  8447,    11,\n",
    "        32151,   338,  4776,   287,   262,   717,   983,   373,   685,  9771,\n",
    "         3129,  1352,     7]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(tokenizer.decode([ 4821,   284,   663, 24000,  7508,    11,   257,  6131,   286, 12014,\n",
    "          468,  8646, 14653,   583,  7351,    13,  1002,   257,  5867,    70,\n",
    "         6131,   468,   642, 43096,    11,   703,   867, 16379,   460,   345,\n",
    "         4483,   611,   534,  4445, 28740,  2496,   318,  4751,   290,   345,\n",
    "          423,  1541, 13529, 21431, 14653,    30]))\n",
    "\n",
    "print(tokenizer.decode([  198,   198,  8600,   416,  2239, 14607,    25,   383,   717,   983,\n",
    "          373,   379, 32151,   338,  1363,  2184,    11,   290,   262,  1218,\n",
    "          983,   373,   379, 21946,   338,  1363,  2184,    13,  8447,    11,\n",
    "        32151,   338,  4776,   287,   262,   717,   983,   373,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   317,  6131,   286,\n",
    "        12014,   468,  8646, 14653,   583,  7351,    13,  8447,    11,   611,\n",
    "          345,   460,  4483,   642, 11668,    11,   340,   468,   685,  9771,\n",
    "         3129,  1352,     7]))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(tokenizer.decode([ 2953, 31908,   338,  2156,    11,   612,   318,  5403,   355,   881,\n",
    "        11676,   355,  6463,  8506,    13,   679,   468,   257,  2472,   286,\n",
    "         2319,  6463,  8506,   287,   465,  2156,    13, 31908,  5839,  3126,\n",
    "          517,  6463,  8506,   379,   262,  3650,   290,  2319,  7380,  1162,\n",
    "         5907,   621,   262,  1271,   286,  6463,  8506,    13,  9938,   262,\n",
    "         5929,  2472,   286,   262,  1271,   286,  1162,  5907,   290,  6463,\n",
    "         8506, 31908,   468,   287,   262,  2156,    30]))\n",
    "\n",
    "print(tokenizer.decode([  198,   198,  8600,   416,  2239, 14607,    25,   383,   717,   983,\n",
    "          373,   379, 32151,   338,  1363,  2184,    11,   290,   262,  1218,\n",
    "          983,   373,   379, 21946,   338,  1363,  2184,    13,  8447,    11,\n",
    "        32151,   338,  4776,   287,   262,   717,   983,   373,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   317,  6131,   286,\n",
    "        12014,   468,  8646, 14653,   583,  7351,    13,  8447,    11,   611,\n",
    "          345,   460,  4483,   642, 11668,    11,   340,   468,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25, 31908,   468,   685,\n",
    "         9771,  3129,  1352,     7]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(tokenizer.decode([  44, 3093,   77,  338,  717, 1700, 2702,  838, 1661,  355,  867, 9088,\n",
    "         355, 2113, 1940,  338,   13, 1002,  484, 2702, 9193,   11,  830, 9088,\n",
    "        5929,   11,  703,  867, 9088,  750, 2113, 1940, 3677,   30]))\n",
    "\n",
    "print(tokenizer.decode([  198,   198,  8600,   416,  2239, 14607,    25,   383,   717,   983,\n",
    "          373,   379, 32151,   338,  1363,  2184,    11,   290,   262,  1218,\n",
    "          983,   373,   379, 21946,   338,  1363,  2184,    13,  8447,    11,\n",
    "        32151,   338,  4776,   287,   262,   717,   983,   373,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   317,  6131,   286,\n",
    "        12014,   468,  8646, 14653,   583,  7351,    13,  8447,    11,   611,\n",
    "          345,   460,  4483,   642, 11668,    11,   340,   468,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25, 31908,   468,   685,\n",
    "         9771,  3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   685,  9771,  3129,\n",
    "         1352,     7]))\n",
    "\n",
    "\n",
    "print(tokenizer.decode([  198,   198,  8600,   416,  2239, 14607,    25,   383,   717,   983,\n",
    "          373,   379, 32151,   338,  1363,  2184,    11,   290,   262,  1218,\n",
    "          983,   373,   379, 21946,   338,  1363,  2184,    13,  8447,    11,\n",
    "        32151,   338,  4776,   287,   262,   717,   983,   373,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   317,  6131,   286,\n",
    "        12014,   468,  8646, 14653,   583,  7351,    13,  8447,    11,   611,\n",
    "          345,   460,  4483,   642, 11668,    11,   340,   468,   685,  9771,\n",
    "         3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25, 31908,   468,   685,\n",
    "         9771,  3129,  1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   685,  9771,  3129,\n",
    "         1352,     7],[  198,   198,  8600,   416,  2239, 14607,    25,   383,  1271,   286,\n",
    "        14878,   326,  4422,   468,  4978,   318,   685,  9771,  3129,  1352,\n",
    "            7]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldtoolvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
