{'Embedding Layer': ['transformer.wte.weight'],
 'Layer 0': ['transformer.h.0.ln_1.weight',
  'transformer.h.0.ln_1.bias',
  'transformer.h.0.attn.k_proj.weight',
  'transformer.h.0.attn.v_proj.weight',
  'transformer.h.0.attn.q_proj.weight',
  'transformer.h.0.attn.out_proj.weight',
  'transformer.h.0.mlp.fc_in.weight',
  'transformer.h.0.mlp.fc_in.bias',
  'transformer.h.0.mlp.fc_out.weight',
  'transformer.h.0.mlp.fc_out.bias'],
 'Layer 1': ['transformer.h.1.ln_1.weight',
  'transformer.h.1.ln_1.bias',
  'transformer.h.1.attn.k_proj.weight',
  'transformer.h.1.attn.v_proj.weight',
  'transformer.h.1.attn.q_proj.weight',
  'transformer.h.1.attn.out_proj.weight',
  'transformer.h.1.mlp.fc_in.weight',
  'transformer.h.1.mlp.fc_in.bias',
  'transformer.h.1.mlp.fc_out.weight',
  'transformer.h.1.mlp.fc_out.bias'],
 'Layer 2': ['transformer.h.2.ln_1.weight',
  'transformer.h.2.ln_1.bias',
  'transformer.h.2.attn.k_proj.weight',
  'transformer.h.2.attn.v_proj.weight',
  'transformer.h.2.attn.q_proj.weight',
  'transformer.h.2.attn.out_proj.weight',
  'transformer.h.2.mlp.fc_in.weight',
  'transformer.h.2.mlp.fc_in.bias',
  'transformer.h.2.mlp.fc_out.weight',
  'transformer.h.2.mlp.fc_out.bias'],
 'Layer 3': ['transformer.h.3.ln_1.weight',
  'transformer.h.3.ln_1.bias',
  'transformer.h.3.attn.k_proj.weight',
  'transformer.h.3.attn.v_proj.weight',
  'transformer.h.3.attn.q_proj.weight',
  'transformer.h.3.attn.out_proj.weight',
  'transformer.h.3.mlp.fc_in.weight',
  'transformer.h.3.mlp.fc_in.bias',
  'transformer.h.3.mlp.fc_out.weight',
  'transformer.h.3.mlp.fc_out.bias'],
 'Layer 4': ['transformer.h.4.ln_1.weight',
  'transformer.h.4.ln_1.bias',
  'transformer.h.4.attn.k_proj.weight',
  'transformer.h.4.attn.v_proj.weight',
  'transformer.h.4.attn.q_proj.weight',
  'transformer.h.4.attn.out_proj.weight',
  'transformer.h.4.mlp.fc_in.weight',
  'transformer.h.4.mlp.fc_in.bias',
  'transformer.h.4.mlp.fc_out.weight',
  'transformer.h.4.mlp.fc_out.bias'],
 'Layer 5': ['transformer.h.5.ln_1.weight',
  'transformer.h.5.ln_1.bias',
  'transformer.h.5.attn.k_proj.weight',
  'transformer.h.5.attn.v_proj.weight',
  'transformer.h.5.attn.q_proj.weight',
  'transformer.h.5.attn.out_proj.weight',
  'transformer.h.5.mlp.fc_in.weight',
  'transformer.h.5.mlp.fc_in.bias',
  'transformer.h.5.mlp.fc_out.weight',
  'transformer.h.5.mlp.fc_out.bias'],
 'Layer 6': ['transformer.h.6.ln_1.weight',
  'transformer.h.6.ln_1.bias',
  'transformer.h.6.attn.k_proj.weight',
  'transformer.h.6.attn.v_proj.weight',
  'transformer.h.6.attn.q_proj.weight',
  'transformer.h.6.attn.out_proj.weight',
  'transformer.h.6.mlp.fc_in.weight',
  'transformer.h.6.mlp.fc_in.bias',
  'transformer.h.6.mlp.fc_out.weight',
  'transformer.h.6.mlp.fc_out.bias'],
 'Layer 7': ['transformer.h.7.ln_1.weight',
  'transformer.h.7.ln_1.bias',
  'transformer.h.7.attn.k_proj.weight',
  'transformer.h.7.attn.v_proj.weight',
  'transformer.h.7.attn.q_proj.weight',
  'transformer.h.7.attn.out_proj.weight',
  'transformer.h.7.mlp.fc_in.weight',
  'transformer.h.7.mlp.fc_in.bias',
  'transformer.h.7.mlp.fc_out.weight',
  'transformer.h.7.mlp.fc_out.bias'],
 'Layer 8': ['transformer.h.8.ln_1.weight',
  'transformer.h.8.ln_1.bias',
  'transformer.h.8.attn.k_proj.weight',
  'transformer.h.8.attn.v_proj.weight',
  'transformer.h.8.attn.q_proj.weight',
  'transformer.h.8.attn.out_proj.weight',
  'transformer.h.8.mlp.fc_in.weight',
  'transformer.h.8.mlp.fc_in.bias',
  'transformer.h.8.mlp.fc_out.weight',
  'transformer.h.8.mlp.fc_out.bias'],
 'Layer 9': ['transformer.h.9.ln_1.weight',
  'transformer.h.9.ln_1.bias',
  'transformer.h.9.attn.k_proj.weight',
  'transformer.h.9.attn.v_proj.weight',
  'transformer.h.9.attn.q_proj.weight',
  'transformer.h.9.attn.out_proj.weight',
  'transformer.h.9.mlp.fc_in.weight',
  'transformer.h.9.mlp.fc_in.bias',
  'transformer.h.9.mlp.fc_out.weight',
  'transformer.h.9.mlp.fc_out.bias'],
 'Layer 10': ['transformer.h.10.ln_1.weight',
  'transformer.h.10.ln_1.bias',
  'transformer.h.10.attn.k_proj.weight',
  'transformer.h.10.attn.v_proj.weight',
  'transformer.h.10.attn.q_proj.weight',
  'transformer.h.10.attn.out_proj.weight',
  'transformer.h.10.mlp.fc_in.weight',
  'transformer.h.10.mlp.fc_in.bias',
  'transformer.h.10.mlp.fc_out.weight',
  'transformer.h.10.mlp.fc_out.bias'],
 'Layer 11': ['transformer.h.11.ln_1.weight',
  'transformer.h.11.ln_1.bias',
  'transformer.h.11.attn.k_proj.weight',
  'transformer.h.11.attn.v_proj.weight',
  'transformer.h.11.attn.q_proj.weight',
  'transformer.h.11.attn.out_proj.weight',
  'transformer.h.11.mlp.fc_in.weight',
  'transformer.h.11.mlp.fc_in.bias',
  'transformer.h.11.mlp.fc_out.weight',
  'transformer.h.11.mlp.fc_out.bias'],
 'Layer 12': ['transformer.h.12.ln_1.weight',
  'transformer.h.12.ln_1.bias',
  'transformer.h.12.attn.k_proj.weight',
  'transformer.h.12.attn.v_proj.weight',
  'transformer.h.12.attn.q_proj.weight',
  'transformer.h.12.attn.out_proj.weight',
  'transformer.h.12.mlp.fc_in.weight',
  'transformer.h.12.mlp.fc_in.bias',
  'transformer.h.12.mlp.fc_out.weight',
  'transformer.h.12.mlp.fc_out.bias'],
 'Layer 13': ['transformer.h.13.ln_1.weight',
  'transformer.h.13.ln_1.bias',
  'transformer.h.13.attn.k_proj.weight',
  'transformer.h.13.attn.v_proj.weight',
  'transformer.h.13.attn.q_proj.weight',
  'transformer.h.13.attn.out_proj.weight',
  'transformer.h.13.mlp.fc_in.weight',
  'transformer.h.13.mlp.fc_in.bias',
  'transformer.h.13.mlp.fc_out.weight',
  'transformer.h.13.mlp.fc_out.bias'],
 'Layer 14': ['transformer.h.14.ln_1.weight',
  'transformer.h.14.ln_1.bias',
  'transformer.h.14.attn.k_proj.weight',
  'transformer.h.14.attn.v_proj.weight',
  'transformer.h.14.attn.q_proj.weight',
  'transformer.h.14.attn.out_proj.weight',
  'transformer.h.14.mlp.fc_in.weight',
  'transformer.h.14.mlp.fc_in.bias',
  'transformer.h.14.mlp.fc_out.weight',
  'transformer.h.14.mlp.fc_out.bias'],
 'Layer 15': ['transformer.h.15.ln_1.weight',
  'transformer.h.15.ln_1.bias',
  'transformer.h.15.attn.k_proj.weight',
  'transformer.h.15.attn.v_proj.weight',
  'transformer.h.15.attn.q_proj.weight',
  'transformer.h.15.attn.out_proj.weight',
  'transformer.h.15.mlp.fc_in.weight',
  'transformer.h.15.mlp.fc_in.bias',
  'transformer.h.15.mlp.fc_out.weight',
  'transformer.h.15.mlp.fc_out.bias'],
 'Layer 16': ['transformer.h.16.ln_1.weight',
  'transformer.h.16.ln_1.bias',
  'transformer.h.16.attn.k_proj.weight',
  'transformer.h.16.attn.v_proj.weight',
  'transformer.h.16.attn.q_proj.weight',
  'transformer.h.16.attn.out_proj.weight',
  'transformer.h.16.mlp.fc_in.weight',
  'transformer.h.16.mlp.fc_in.bias',
  'transformer.h.16.mlp.fc_out.weight',
  'transformer.h.16.mlp.fc_out.bias'],
 'Layer 17': ['transformer.h.17.ln_1.weight',
  'transformer.h.17.ln_1.bias',
  'transformer.h.17.attn.k_proj.weight',
  'transformer.h.17.attn.v_proj.weight',
  'transformer.h.17.attn.q_proj.weight',
  'transformer.h.17.attn.out_proj.weight',
  'transformer.h.17.mlp.fc_in.weight',
  'transformer.h.17.mlp.fc_in.bias',
  'transformer.h.17.mlp.fc_out.weight',
  'transformer.h.17.mlp.fc_out.bias'],
 'Layer 18': ['transformer.h.18.ln_1.weight',
  'transformer.h.18.ln_1.bias',
  'transformer.h.18.attn.k_proj.weight',
  'transformer.h.18.attn.v_proj.weight',
  'transformer.h.18.attn.q_proj.weight',
  'transformer.h.18.attn.out_proj.weight',
  'transformer.h.18.mlp.fc_in.weight',
  'transformer.h.18.mlp.fc_in.bias',
  'transformer.h.18.mlp.fc_out.weight',
  'transformer.h.18.mlp.fc_out.bias'],
 'Layer 19': ['transformer.h.19.ln_1.weight',
  'transformer.h.19.ln_1.bias',
  'transformer.h.19.attn.k_proj.weight',
  'transformer.h.19.attn.v_proj.weight',
  'transformer.h.19.attn.q_proj.weight',
  'transformer.h.19.attn.out_proj.weight',
  'transformer.h.19.mlp.fc_in.weight',
  'transformer.h.19.mlp.fc_in.bias',
  'transformer.h.19.mlp.fc_out.weight',
  'transformer.h.19.mlp.fc_out.bias'],
 'Layer 20': ['transformer.h.20.ln_1.weight',
  'transformer.h.20.ln_1.bias',
  'transformer.h.20.attn.k_proj.weight',
  'transformer.h.20.attn.v_proj.weight',
  'transformer.h.20.attn.q_proj.weight',
  'transformer.h.20.attn.out_proj.weight',
  'transformer.h.20.mlp.fc_in.weight',
  'transformer.h.20.mlp.fc_in.bias',
  'transformer.h.20.mlp.fc_out.weight',
  'transformer.h.20.mlp.fc_out.bias'],
 'Layer 21': ['transformer.h.21.ln_1.weight',
  'transformer.h.21.ln_1.bias',
  'transformer.h.21.attn.k_proj.weight',
  'transformer.h.21.attn.v_proj.weight',
  'transformer.h.21.attn.q_proj.weight',
  'transformer.h.21.attn.out_proj.weight',
  'transformer.h.21.mlp.fc_in.weight',
  'transformer.h.21.mlp.fc_in.bias',
  'transformer.h.21.mlp.fc_out.weight',
  'transformer.h.21.mlp.fc_out.bias'],
 'Layer 22': ['transformer.h.22.ln_1.weight',
  'transformer.h.22.ln_1.bias',
  'transformer.h.22.attn.k_proj.weight',
  'transformer.h.22.attn.v_proj.weight',
  'transformer.h.22.attn.q_proj.weight',
  'transformer.h.22.attn.out_proj.weight',
  'transformer.h.22.mlp.fc_in.weight',
  'transformer.h.22.mlp.fc_in.bias',
  'transformer.h.22.mlp.fc_out.weight',
  'transformer.h.22.mlp.fc_out.bias'],
 'Layer 23': ['transformer.h.23.ln_1.weight',
  'transformer.h.23.ln_1.bias',
  'transformer.h.23.attn.k_proj.weight',
  'transformer.h.23.attn.v_proj.weight',
  'transformer.h.23.attn.q_proj.weight',
  'transformer.h.23.attn.out_proj.weight',
  'transformer.h.23.mlp.fc_in.weight',
  'transformer.h.23.mlp.fc_in.bias',
  'transformer.h.23.mlp.fc_out.weight',
  'transformer.h.23.mlp.fc_out.bias'],
 'Layer 24': ['transformer.h.24.ln_1.weight',
  'transformer.h.24.ln_1.bias',
  'transformer.h.24.attn.k_proj.weight',
  'transformer.h.24.attn.v_proj.weight',
  'transformer.h.24.attn.q_proj.weight',
  'transformer.h.24.attn.out_proj.weight',
  'transformer.h.24.mlp.fc_in.weight',
  'transformer.h.24.mlp.fc_in.bias',
  'transformer.h.24.mlp.fc_out.weight',
  'transformer.h.24.mlp.fc_out.bias'],
 'Layer 25': ['transformer.h.25.ln_1.weight',
  'transformer.h.25.ln_1.bias',
  'transformer.h.25.attn.k_proj.weight',
  'transformer.h.25.attn.v_proj.weight',
  'transformer.h.25.attn.q_proj.weight',
  'transformer.h.25.attn.out_proj.weight',
  'transformer.h.25.mlp.fc_in.weight',
  'transformer.h.25.mlp.fc_in.bias',
  'transformer.h.25.mlp.fc_out.weight',
  'transformer.h.25.mlp.fc_out.bias'],
 'Layer 26': ['transformer.h.26.ln_1.weight',
  'transformer.h.26.ln_1.bias',
  'transformer.h.26.attn.k_proj.weight',
  'transformer.h.26.attn.v_proj.weight',
  'transformer.h.26.attn.q_proj.weight',
  'transformer.h.26.attn.out_proj.weight',
  'transformer.h.26.mlp.fc_in.weight',
  'transformer.h.26.mlp.fc_in.bias',
  'transformer.h.26.mlp.fc_out.weight',
  'transformer.h.26.mlp.fc_out.bias'],
 'Layer 27': ['transformer.h.27.ln_1.weight',
  'transformer.h.27.ln_1.bias',
  'transformer.h.27.attn.k_proj.weight',
  'transformer.h.27.attn.v_proj.weight',
  'transformer.h.27.attn.q_proj.weight',
  'transformer.h.27.attn.out_proj.weight',
  'transformer.h.27.mlp.fc_in.weight',
  'transformer.h.27.mlp.fc_in.bias',
  'transformer.h.27.mlp.fc_out.weight',
  'transformer.h.27.mlp.fc_out.bias'],
 'Final Layer Norm': ['transformer.ln_f.weight', 'transformer.ln_f.bias'],
 'LM Head': ['lm_head.weight', 'lm_head.bias']}