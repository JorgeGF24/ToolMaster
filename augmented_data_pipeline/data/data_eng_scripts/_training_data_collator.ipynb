{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE TO GET DATA READY FOR TRAINING\n",
    "\n",
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/jg2619/toolformer-luci/oldtoolvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from beartype import beartype\n",
    "import torch\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "version_name = \"improved\"\n",
    "MODEL_NAME = \"GPTJ\"\n",
    "\n",
    "TOOL_DIRS = {\n",
    "    \"Calculator\": \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/definite_horizon/augmented_prompttrick/calculator_LLAMA\",\n",
    "    \"WikiSearch\": \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/definite_horizon/augmented_prompttrick/wikiSearch_LLAMA\",\n",
    "    \"Calendar\": \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/definite_horizon/augmented_standard/calendar_LLAMA\"\n",
    "}\n",
    "\n",
    "CONSTRUCTION_DIRS = {\n",
    "    \"origin\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/origin\",\n",
    "    \"white space removal\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/white_space_removal\",\n",
    "    \"tool token substitution\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/tool_token_substitution\",\n",
    "    \"token type masking\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/token_type_masking\",\n",
    "    \"calculator subtype\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/calculator_subtype\",  \n",
    "    \"relevance score\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/relevance_score\",    \n",
    "    \"duplicity rankings\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/duplicity_rankings\",\n",
    "    \"curated\":\"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/curated\",\n",
    "}\n",
    "\n",
    "def construction_dir(part):\n",
    "    return os.path.join(CONSTRUCTION_DIRS[part], MODEL_NAME + \"_\" + version_name)\n",
    "\n",
    "def recurse_dict_create_dir():\n",
    "    for key, value in CONSTRUCTION_DIRS.items():\n",
    "        os.makedirs(construction_dir(key), exist_ok=True)\n",
    "\n",
    "recurse_dict_create_dir()\n",
    "\n",
    "TRAIN_FIELDS = [\"tokenized_start_text\", \"tool_name\", \"tokenized_text\", \"token_type\",\"tokenized_end_text\", \"start_token_type\", \"end_token_type\", \"start_method_A_train_mask\", \"end_method_A_train_mask\"]\n",
    "OLD_FIELDS = [\"url\", \"text\", \"API_calls_text\", \"API_call_response_text\", \"position\", \"loss_improvement\", \"arg_cohort\", \"raw_arg\", \"processed_arg\", \"title\", \"date_download\", \"digest\", \"length\", \"nlines\", \"source_domain\", \"cc_segment\", \"original_nlines\", \"original_length\", \"language\", \"language_score\", \"perplexity\", \"bucket\"]\n",
    "DATA_SCIENCE_FIELDS = [\"duplicity_count_tool\", \"duplicity_count_global\", \"duplicity_ranking_tool\", \"duplicity_ranking_global\", \"duplicity_count_stats\", \"duplicity_ranking_stats\"]\n",
    "\n",
    "CALC_SUBTYPES = [\"add\", \"subtract\", \"multiply\", \"divide\", \"add_subtract\", \"mult_divide\", \"mix\"]\n",
    "\n",
    "TOOL_NAMES = [\"Calculator\", \"WikiSearch\", \"Calendar\"]\n",
    "\n",
    "# Copy csv files into TOOL_DIRS to CONSTRUCTION \"origin\" into a MODEL_NAME + \"_\" + version_name folder\n",
    "for tool_name, tool_dir in TOOL_DIRS.items():\n",
    "    if tool_dir is not None:\n",
    "        for file in os.listdir(tool_dir):\n",
    "            if file.endswith(\".csv\") and \"stat\" not in file:\n",
    "                with open(os.path.join(tool_dir, file), \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                with open(os.path.join(construction_dir(\"origin\"), tool_name + \"_\" + file), \"w\") as f:\n",
    "                    f.writelines(lines)\n",
    "\n",
    "cache_dir = \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache\"\n",
    "\n",
    "tokenizers = {\"GPTJ\": AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", truncate=True, max_length=270, cache_dir=cache_dir),\n",
    "              \"LLAMA2\": LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\",\n",
    "                                                   token=\"***REMOVED***\",\n",
    "                                                   cache_dir=cache_dir),}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty experiment dirs if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Empty dirs for new experiment\n",
    "def recurse_dict_delete_data():\n",
    "    for key, value in CONSTRUCTION_DIRS.items():\n",
    "        if value is not None and key != \"origin\":\n",
    "            if os.path.exists(construction_dir(key)):\n",
    "                print(f\"Deleting {construction_dir(key)}\")\n",
    "                shutil.rmtree(construction_dir(key))\n",
    "\n",
    "if False:\n",
    "    recurse_dict_delete_data()\n",
    "    recurse_dict_create_dir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitutes \"[\" for tool tokens.\n",
    "\n",
    "func: tool_token_substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from csv import DictWriter\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "tools = [\"Calculator\", \"WikiSearch\", \"Calendar\"]\n",
    "\n",
    "def tool_tokenize(row, tool):\n",
    "\n",
    "    text = row.API_call_response_text\n",
    "    text_no_resp = row.API_calls_text\n",
    "\n",
    "    if (\"<TOOL>\" in text):\n",
    "        return row\n",
    "                \n",
    "    # regex expression that returns the text until where it matches the API start token followed by the tool name\n",
    "    text = re.sub(rf\"\\[(?={tool[:4]})\", '<TOOL>', text)\n",
    "    text_no_resp = re.sub(rf\"\\[(?={tool[:4]})\", '<TOOL>', text_no_resp)\n",
    "    end_text = re.split(f\"\\)]\", text_no_resp, maxsplit=1)\n",
    "    if len(end_text) != 2:\n",
    "        # If text includes \"<TOOL>\" substring, raise a stub exception\n",
    "        raise Exception(f\"Text does not end with a response token: {text}\")\n",
    "    end_text = end_text[1]\n",
    "    text = text[:-len(end_text)-1] + \"</TOOL>\" + end_text\n",
    "    text_no_resp = text_no_resp[:-len(end_text)-1] + \"</TOOL>\" + end_text\n",
    "\n",
    "    row[\"API_call_response_text\"] = text\n",
    "    row[\"API_calls_text\"] = text_no_resp\n",
    "\n",
    "    return row\n",
    "\n",
    "def tool_token_substitution(input):\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"tool token substitution\")\n",
    "    print(\"Substituting tokens in files in directory: \", input_dir)\n",
    "    for tool in tools:\n",
    "        file_list = [file for file in os.listdir(input_dir) if file.endswith('.csv') and tool.lower() in file.lower()]\n",
    "\n",
    "        # Create an output directory by adding \"processed\" to the input directory\n",
    "        # output_dir = os.path.join(TOOL_DIRS[tool], \"tool_tokenized\")\n",
    "        # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for file in file_list:\n",
    "            print(\"Processing: \", file)\n",
    "            # Load dataset\n",
    "            df = pd.read_csv(os.path.join(input_dir, file))\n",
    "            # dataset = load_dataset(TOOL_DIRS[tool], split=\"train\", data_files = file, cache_dir = cache_dir)\n",
    "            # columns = list(dataset.column_names)\n",
    "            df = df.apply(tool_tokenize, args=(tool,), axis=1)\n",
    "\n",
    "            # Save dataset\n",
    "            df.to_csv(os.path.join(output_dir, file), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removes long whitespaces\n",
    "\n",
    "Requires \\<TOOL\\> tokens\n",
    "\n",
    "white_space_removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script removes long white spaces from the specified fields in the csv files of the \"white space removal\" \"input\" dir.\n",
    "# The output is saved in \"white space removal\" \"output\" dir.\n",
    "# We substitute 5 or more white spaces with 2 white spaces.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_spaces_token_avoider(row):\n",
    "    text = row.text\n",
    "    api_resp = row.API_call_response_text\n",
    "    api_call = row.API_calls_text\n",
    "    \n",
    "    start_sentences = re.findall(r\"(.*?)(\\s{5,})\", text)\n",
    "    resp_start_sentences = re.findall(r\"(.*?)(\\s{5,})\", api_resp)\n",
    "    call_start_sentences = re.findall(r\"(.*?)(\\s{5,})\", api_call)\n",
    "    if len(start_sentences) == 0:\n",
    "        return row\n",
    "\n",
    "    # Else, loop through\n",
    "    # Assumes the 5 white spaces are not inside the API call\n",
    "    else:\n",
    "        if len(start_sentences) != len(resp_start_sentences) or len(start_sentences) != len(call_start_sentences):\n",
    "            api_resp = re.sub(r\"(\\s{0,})(<TOOL>.*?</TOOL>)(\\s{0,})\", r\"  \\2 \", api_resp)\n",
    "            api_call = re.sub(r\"(\\s{0,})(<TOOL>.*?</TOOL>)(\\s{0,})\", r\"  \\2 \", api_call)\n",
    "        \n",
    "        # Substitute all 5 or more white spaces with 2 white spaces:\n",
    "        text = re.sub(r\"\\s{5,}\", \"  \", text)\n",
    "        api_resp = re.sub(r\"\\s{5,}\", \"  \", api_resp)\n",
    "        api_call = re.sub(r\"\\s{5,}\", \"  \", api_call)\n",
    "        # Assumes the 5 white spaces are not inside the API call\n",
    "\n",
    "        row.text = text\n",
    "        row.API_call_response_text = api_resp\n",
    "        row.API_calls_text = api_call\n",
    "\n",
    "        return row\n",
    "\n",
    "# TEST\n",
    "#data = {\"text\": \"Hello this        is my      name\", \"API_call_response_text\": \"Hello this    <TOOL>LOOOOOL hwen        welcome to the jungle</TOOL>    is my      name\", \"API_calls_text\": \"Hello this<TOOL>LOOOOOL hwen        welcome to the jungle</TOOL>        is my      name\"}\n",
    "#df = pd.DataFrame(data, index=[0])\n",
    "#print(remove_spaces_token_avoider(df.iloc[0]))\n",
    "\n",
    "def white_space_removal(input):\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"white space removal\")\n",
    "    print(f\"Removing long white spaces from {input_dir} and saving to {output_dir}\")\n",
    "    file_list = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "    for file in file_list:\n",
    "        print(f\"Processing {file}\")\n",
    "        df = pd.read_csv(os.path.join(input_dir, file))\n",
    "\n",
    "        df = df.apply(remove_spaces_token_avoider, axis=1)\n",
    "        df.to_csv(os.path.join(output_dir, file), index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify and tag text with API calls into token types (0,...9)\n",
    "\n",
    "\n",
    "Require that data has \\<TOOL\\> tokens instead of \"[\"\n",
    "\n",
    "Func token_type_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script readies the data for training. It takes the raw data from the dataset and converts it into a format that can be used by the model.\n",
    "\n",
    "from csv import DictWriter\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from beartype import beartype\n",
    "from typing import List, Dict, Tuple, Union, Optional, Any\n",
    "\n",
    "\n",
    "def TOOL_START_TOKEN(tool_name):\n",
    "    return rf\"\\s\\[(?={re.escape(tool_name)})\"            #  \" <TOOL>\"\n",
    "\n",
    "TOOL_START_TOKEN = \" <TOOL>\"\n",
    "TOOL_END_TOKEN = \"</TOOL>\" \n",
    "\n",
    "tokenizers[MODEL_NAME].add_tokens([TOOL_START_TOKEN, TOOL_END_TOKEN, \"[PAD]\"])\n",
    "\n",
    "\n",
    "\n",
    "@beartype\n",
    "def mask_tokenize_data(\n",
    "        call_response_texts:List[str],\n",
    "        tool_name:str,\n",
    "        tokenizer\n",
    "):\n",
    "    global TOOL_END_TOKEN, TRAIN_FIELDS\n",
    "\n",
    "    output = []\n",
    "    for i, text in enumerate(call_response_texts):\n",
    "        new_row = {}\n",
    "\n",
    "        # Substitute \"Calendar()\" in text for \"Calendar ( )\"\n",
    "        text = text.replace(\"Calendar()\", \"Calendar( )\")\n",
    "        \n",
    "        tokenized_text = tokenizer.encode(text, truncation=True, max_length=1000)\n",
    "        #for token in tokenized_text[model_names[0]]:\n",
    "        #    print(f\"{token:<5}: {tokenizers['GPTJ'].decode([token])}\")\n",
    "\n",
    "        # Find index where tokenized_text matches the tool start token:\n",
    "        try:\n",
    "            tool_token_index = tokenized_text.index(tokenizer.encode(TOOL_START_TOKEN)[0])\n",
    "            index_arrow = tokenized_text[tool_token_index:].index(tokenizer.encode(\"→\")[0]) + tool_token_index\n",
    "            index_end = tokenized_text[index_arrow:].index(tokenizer.encode(TOOL_END_TOKEN)[0]) + index_arrow\n",
    "        except ValueError as e:\n",
    "            print(\"ValueError\", flush=True)\n",
    "            print(text, flush=True)\n",
    "            raise e\n",
    "\n",
    "\n",
    "        len_toolname = len(tokenizer.encode(tool_name))\n",
    "\n",
    "        # Find number of ocurrences of →\n",
    "        occurrences = len(re.findall(r'(\\)\\→)', text))\n",
    "\n",
    "        if occurrences != 1:\n",
    "            print(\"More than one occurrence of →\", flush=True)\n",
    "            print(text, flush=True)\n",
    "            raise Exception(\"More than one occurrence of →\")\n",
    "\n",
    "        # Create token type mask\n",
    "        token_type = torch.zeros(len(tokenized_text))\n",
    "                                                        # 0 for data...\n",
    "        token_type[tool_token_index] += 1                         # 1 for <TOOL>\n",
    "        token_type[tool_token_index+1] += 1                       # 2 for Toolname\n",
    "        token_type[tool_token_index+1+len_toolname] += 1          # 3 for (\n",
    "        token_type[tool_token_index+1 + len_toolname + 1] += 1    # 4 for args\n",
    "        token_type[index_arrow - 1] += 1                   # 5 for )\n",
    "        token_type[index_arrow] += 1                       # 6 for →\n",
    "        token_type[index_arrow+1] += 1                     # 7 for response\n",
    "        token_type[index_end] += 1                         # 8 for </TOOL>\n",
    "        token_type[index_end+1] += 1                       # 9 for ...Data\n",
    "        token_type = token_type.cumsum(dim=0)\n",
    "\n",
    "        new_row[\"token_type\"] = token_type.view(-1).long().tolist()\n",
    "        new_row[\"tokenized_text\"] = tokenized_text\n",
    "\n",
    "        new_row[\"start_method_A_train_mask\"] = (token_type[:tool_token_index+1] < 2).view(-1).long().tolist()\n",
    "        new_row[\"end_method_A_train_mask\"] = (token_type[tool_token_index+1+len_toolname] > 2).view(-1).long().tolist()\n",
    "        new_row[\"tokenized_start_text\"] = tokenized_text[:tool_token_index+1]\n",
    "        new_row[\"tokenized_end_text\"] = tokenized_text[index_end+1:]\n",
    "        new_row[\"start_token_type\"] = token_type[:tool_token_index+1].view(-1).long().tolist()\n",
    "        new_row[\"end_token_type\"] = token_type[tool_token_index+1+len_toolname].view(-1).long().tolist()\n",
    "    \n",
    "        new_row[\"tool_name\"] = tool_name\n",
    "\n",
    "        output.append(new_row)\n",
    "\n",
    "    return output\n",
    "\n",
    "tool_names = [\"Calendar\", \"WikiSearch\", \"Calculator\"]\n",
    "\n",
    "def token_type_masking(input):\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"token type masking\")\n",
    "\n",
    "    print(f\"Token type masking {input_dir} to {output_dir}\", flush=True)\n",
    "\n",
    "    # We want to output: tokenized_start_text, tool_name, tokenized_end_text, token_type, start_method_A_train_mask, end_method_A_train_mask\n",
    "\n",
    "    def null_permitting_collate_fn(batch):\n",
    "        dict_of_lists = {key: [] for key in batch[0].keys()}\n",
    "\n",
    "        for d in batch:\n",
    "            for key, value in d.items():\n",
    "                dict_of_lists[key].append(value)\n",
    "        \n",
    "        return dict_of_lists\n",
    "        \n",
    "\n",
    "    output_data = []\n",
    "\n",
    "    for tool in tool_names:\n",
    "        file_list = [file for file in os.listdir(input_dir) if tool in file]\n",
    "        if tool == \"Calendar\":\n",
    "            file_list = file_list[:4]\n",
    "        \n",
    "        print(f\"Processing {tool} with {len(file_list)} files\", flush=True)\n",
    "        \n",
    "        dataset = load_dataset(input_dir, data_files = file_list, split=\"train\", cache_dir=cache_dir)\n",
    "\n",
    "        dl = DataLoader(dataset, batch_size=1000, collate_fn=null_permitting_collate_fn, shuffle=False)\n",
    "\n",
    "        data_iter = iter(dl)\n",
    "        data = next(data_iter, None)\n",
    "        \n",
    "        while data is not None:\n",
    "            train_data = mask_tokenize_data(data[\"API_call_response_text\"], \n",
    "                                            tool, \n",
    "                                            tokenizers[MODEL_NAME],)\n",
    "\n",
    "            for i, output_row in enumerate(train_data):\n",
    "                new_row = {key: output_row[key] for key in TRAIN_FIELDS}\n",
    "                for key in OLD_FIELDS:\n",
    "                    new_row[key] = data[key][i]\n",
    "                # This key is the decoded sentence from tokens of type 0 and 9\n",
    "                # Extract this with masked select. Decode with tokenizers[\"GPTJ\"].decode()\n",
    "\n",
    "                output_data.append(new_row)\n",
    "\n",
    "            data = next(data_iter, None)\n",
    "\n",
    "\n",
    "    # Create output file:\n",
    "    with open(f'{output_dir}/train.csv', 'w') as f:\n",
    "        writer = DictWriter(f, fieldnames=OLD_FIELDS+TRAIN_FIELDS+DATA_SCIENCE_FIELDS)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in output_data:\n",
    "            if row[\"tool_name\"] == \"Calendar\":\n",
    "                #row[\"arg\"] = \" \"\n",
    "                row[\"arg_cohort\"] = []\n",
    "                #del row[\"date\"]\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to tag training data (tagged with token types) from tool type Calculator with operation type labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag tool type from calculator\n",
    "\n",
    "import ast\n",
    "\n",
    "from csv import DictWriter\n",
    "\n",
    "from datasets import Value, Features\n",
    "\n",
    "\n",
    "tokenizer = tokenizers[MODEL_NAME]\n",
    "\n",
    "def calculator_subtype(input):\n",
    "\n",
    "    print(\"Starting calculator subtype......\")\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"calculator subtype\")\n",
    "    # Files in input_dir that end with .csv\n",
    "    data_files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]  #if f.endswith(f\"train_{version_name}.csv\")\n",
    "    print(data_files)\n",
    "\n",
    "    feat_dict = {'url': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'API_calls_text': Value(dtype='string', id=None), 'API_call_response_text': Value(dtype='string', id=None), 'position': Value(dtype='float64', id=None), 'loss_improvement': Value(dtype='float64', id=None), 'processed_arg': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'date_download': Value(dtype='string', id=None), 'digest': Value(dtype='string', id=None), 'length': Value(dtype='int64', id=None), 'nlines': Value(dtype='int64', id=None), 'source_domain': Value(dtype='string', id=None), 'cc_segment': Value(dtype='string', id=None), 'original_nlines': Value(dtype='int64', id=None), 'original_length': Value(dtype='int64', id=None), 'language': Value(dtype='string', id=None), 'language_score': Value(dtype='float64', id=None), 'perplexity': Value(dtype='float64', id=None), 'bucket': Value(dtype='string', id=None)}\n",
    "    for key in TRAIN_FIELDS + DATA_SCIENCE_FIELDS:\n",
    "        feat_dict[key] = Value(dtype='string', id=None)\n",
    "    features = Features(feat_dict)\n",
    "\n",
    "    for file in data_files:\n",
    "        # Load data\n",
    "        print(f\"Loading {file}\")\n",
    "        \n",
    "        dataset = load_dataset(input_dir, data_files=file, split=\"train\", cache_dir=cache_dir, features=features)\n",
    "\n",
    "        header = dataset.column_names + [\"op_label\", \"ops_used\"]\n",
    "\n",
    "        with open(os.path.join(output_dir, file), \"w\") as f:\n",
    "            # Dict writer\n",
    "            writer = DictWriter(f, fieldnames=header)\n",
    "\n",
    "            # Write header\n",
    "            writer.writeheader()\n",
    "\n",
    "            for row in dataset:\n",
    "                if row[\"tool_name\"] != \"Calculator\":\n",
    "                    row[\"op_label\"] = \"NotApplicable\"\n",
    "                    row[\"ops_used\"] = \"NotApplicable\"\n",
    "                    writer.writerow(row)\n",
    "                    continue\n",
    "                token_type = ast.literal_eval(row[\"token_type\"])\n",
    "                tokenized_text = ast.literal_eval(row[\"tokenized_text\"])\n",
    "\n",
    "                # Args are tokens marked with token_type 4\n",
    "                args = [tokenized_text[i] for i, t in enumerate(token_type) if t == 4]\n",
    "                args = tokenizer.decode(args)\n",
    "\n",
    "                ops = [0,0,0,0]\n",
    "\n",
    "                for character in args:\n",
    "                    if character == \"+\":\n",
    "                        ops[0] += 1\n",
    "                    elif character == \"-\":\n",
    "                        ops[1] += 1\n",
    "                    elif character == \"*\":\n",
    "                        ops[2] += 1\n",
    "                    elif character == \"/\":\n",
    "                        ops[3] += 1\n",
    "\n",
    "                # Labels:\n",
    "                # add: if ops[0] > 0 and ops[1] == 0 and ops[2] == 0 and ops[3] == 0\n",
    "                # subtract: if ops[0] == 0 and ops[1] > 0 and ops[2] == 0 and ops[3] == 0\n",
    "                # multiply: if ops[0] == 0 and ops[1] == 0 and ops[2] > 0 and ops[3] == 0\n",
    "                # divide: if ops[0] == 0 and ops[1] == 0 and ops[2] == 0 and ops[3] > 0\n",
    "                # add_subtract: if ops[0] > 0 and ops[1] > 0 and ops[2] == 0 and ops[3] == 0\n",
    "                # mult_divide: if ops[0] == 0 and ops[1] == 0 and ops[2] > 0 and ops[3] > 0\n",
    "                # mix: else\n",
    "\n",
    "                if ops[0] > 0 and ops[1] == 0 and ops[2] == 0 and ops[3] == 0:\n",
    "                    label = \"add\"\n",
    "                elif ops[0] == 0 and ops[1] > 0 and ops[2] == 0 and ops[3] == 0:\n",
    "                    label = \"subtract\"\n",
    "                elif ops[0] == 0 and ops[1] == 0 and ops[2] > 0 and ops[3] == 0:\n",
    "                    label = \"multiply\"\n",
    "                elif ops[0] == 0 and ops[1] == 0 and ops[2] == 0 and ops[3] > 0:\n",
    "                    label = \"divide\"\n",
    "                elif ops[0] > 0 and ops[1] > 0 and ops[2] == 0 and ops[3] == 0:\n",
    "                    label = \"add_subtract\"\n",
    "                elif ops[0] == 0 and ops[1] == 0 and ops[2] > 0 and ops[3] > 0:\n",
    "                    label = \"mult_divide\"\n",
    "                else:\n",
    "                    label = \"mix\"\n",
    "                \n",
    "                row[\"op_label\"] = label\n",
    "                row[\"ops_used\"] = ops\n",
    "                \n",
    "                writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data relevance score\n",
    "\n",
    "This script assigns a relevance score to the data points based on a custom metric\n",
    "\n",
    "Requires calc_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIIIIIIIIIIN\n",
      "Starting relevance score calculation...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 154\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMAIIIIIIIIIIN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m     relevance_score(\u001b[39m\"\u001b[39;49m\u001b[39mcalculator subtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, plots\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mrelevance_score\u001b[0;34m(input, plots)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Read csv file into a dataframe\u001b[39;00m\n\u001b[1;32m     15\u001b[0m file \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(input_dir) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m---> 16\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(file) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     17\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_dir, file[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     19\u001b[0m calc_df \u001b[39m=\u001b[39m df[df[\u001b[39m\"\u001b[39m\u001b[39mtool_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCalculator\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualize training data.\n",
    "# Open csv files in construction_dir(\"origin\") into one dataframe per tool. For each tool, the filenames will contain the tool name.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def relevance_score(input, plots = False):\n",
    "    tools = [\"calculator\", \"calendar\", \"wikisearch\"]\n",
    "\n",
    "    print(\"Starting relevance score calculation...\")\n",
    "\n",
    "    input_dir = construction_dir(input)\n",
    "\n",
    "    # Read csv file into a dataframe\n",
    "    file = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "    assert len(file) == 1\n",
    "    df = pd.read_csv(os.path.join(input_dir, file[0]))\n",
    "\n",
    "    calc_df = df[df[\"tool_name\"] == \"Calculator\"]\n",
    "    calendar_df = df[df[\"tool_name\"] == \"Calendar\"]\n",
    "    wikisearch_df = df[df[\"tool_name\"] == \"WikiSearch\"]\n",
    "\n",
    "    # Len of each df:\n",
    "    print(f\"Len of calc_df: {len(calc_df)}, len of calendar_df: {len(calendar_df)}, len of wikisearch_df: {len(wikisearch_df)}\")\n",
    "    \n",
    "    calc_m = 0.003\n",
    "    calc_c = 0.6\n",
    "    calend_m = 0.013\n",
    "    calend_c = 1.3\n",
    "    wiki_m = 0.015\n",
    "    wiki_c = -0.7\n",
    "    calc_bounds = (1.3, 0.5)\n",
    "    calend_bounds = (1.8, 2)\n",
    "    wiki_bounds = (3.8, 2.2)\n",
    "\n",
    "\n",
    "    # Define a relevance metric for each tool. It is based on the line in the scatter plot. \n",
    "    # The metric assigns to each point the distance to the line.\n",
    "    # Points above the line have a positive sign, points below the line have a negative sign.\n",
    "\n",
    "    # Create a new column in the dataframe for the relevance metric\n",
    "    calc_theta = np.arctan(calc_m)\n",
    "    calend_theta = np.arctan(calend_m)\n",
    "    wiki_theta = np.arctan(wiki_m)\n",
    "\n",
    "    #calc_df.loc[:,\"x\"] = np.cos(calc_theta) * calc_df.perplexity + np.sin(calc_theta) * calc_df.loss_improvement\n",
    "    calc_df.loc[:,\"relevance\"] = - np.sin(calc_theta) * calc_df.perplexity + np.cos(calc_theta) * (calc_df.loss_improvement  - calc_c)\n",
    "    calendar_df.loc[:,\"relevance\"] = - np.sin(calend_theta) * calendar_df[\"perplexity\"] + np.cos(calend_theta) * (calendar_df[\"loss_improvement\"]  - calend_c)\n",
    "    wikisearch_df.loc[:,\"relevance\"] = - np.sin(wiki_theta) * wikisearch_df[\"perplexity\"] + np.cos(wiki_theta) * (wikisearch_df[\"loss_improvement\"]  - wiki_c)\n",
    "\n",
    "    # Normalize relevance by putting the minimum value to 0 and the maximum value to 1:\n",
    "    # df.loc[:,\"relevance\"] = (df.relevance - df.relevance.min()) / (df.relevance.max() - df.relevance.min())\n",
    "\n",
    "    # A more sophisticated normalization:\n",
    "    indices = (calc_df.relevance > -calc_bounds[1]) & (calc_df.relevance < calc_bounds[0])\n",
    "    calc_averg_thr = np.mean(calc_df[indices].relevance)\n",
    "    indices = (calendar_df.relevance > -calend_bounds[1]) & (calendar_df.relevance < calend_bounds[0])\n",
    "    calend_averg_thr = np.mean(calendar_df[indices].relevance)\n",
    "    indices = (wikisearch_df.relevance > -wiki_bounds[1]) & (wikisearch_df.relevance < wiki_bounds[0])\n",
    "    wiki_averg_thr = np.mean(wikisearch_df[indices].relevance)\n",
    "\n",
    "    # Normalize relevance by putting their averages to 1\n",
    "    #calc_df.loc[:,\"relevance\"] = (calc_df.relevance+calc_averg_thr-abs(calc_averg_thr)) / abs(calc_averg_thr)\n",
    "    #calendar_df.loc[:,\"relevance\"] = (calendar_df.relevance+calend_averg_thr-abs(calend_averg_thr)) / abs(calend_averg_thr)\n",
    "    #wikisearch_df.loc[:,\"relevance\"] = (wikisearch_df.relevance+wiki_averg_thr-abs(wiki_averg_thr)) / abs(wiki_averg_thr)\n",
    "\n",
    "    # Normalize by bringing minimum to -1:\n",
    "    calc_extreme_max = np.mean(calc_df[calc_df.relevance > calc_bounds[0]].relevance)\n",
    "    calc_extreme_min = np.mean(calc_df[calc_df.relevance < calc_bounds[1]].relevance)\n",
    "    calc_df.loc[:,\"relevance\"] = (calc_df.relevance - calc_extreme_min) / (calc_extreme_max - calc_extreme_min) * 2 - 1\n",
    "    calend_extreme_max = np.mean(calendar_df[calendar_df.relevance > calend_bounds[0]].relevance)\n",
    "    calend_extreme_min = np.mean(calendar_df[calendar_df.relevance < calend_bounds[1]].relevance)\n",
    "    calendar_df.loc[:,\"relevance\"] = (calendar_df.relevance - calend_extreme_min) / (calend_extreme_max - calend_extreme_min) * 2 - 1\n",
    "    wiki_extreme_max = np.mean(wikisearch_df[wikisearch_df.relevance > wiki_bounds[0]].relevance)\n",
    "    wiki_extreme_min = np.mean(wikisearch_df[wikisearch_df.relevance < wiki_bounds[1]].relevance)\n",
    "    wikisearch_df.loc[:,\"relevance\"] = (wikisearch_df.relevance - wiki_extreme_min) / (wiki_extreme_max - wiki_extreme_min) * 2 - 0.8 \n",
    "\n",
    "    df = pd.concat([calc_df, calendar_df, wikisearch_df])\n",
    "\n",
    "    output_dir = construction_dir(\"relevance score\")\n",
    "    # Save data frame into a csv file\n",
    "    df.to_csv(os.path.join(output_dir, file[0]), index=False)\n",
    "\n",
    "    if plots:\n",
    "\n",
    "        # Scatter colour depends on relevance score\n",
    "        #df[\"scatter colour\"] = plt.cm.cool(df[\"relevance\"])\n",
    "\n",
    "        calendar_df = df[df[\"tool_name\"] == \"Calendar\"]\n",
    "        wikisearch_df = df[df[\"tool_name\"] == \"WikiSearch\"]\n",
    "        calc_df = df[df[\"tool_name\"] == \"Calculator\"]\n",
    "\n",
    "        calc_fig, calc_ax = plt.subplots(figsize=(8,5))\n",
    "        calc_sub_fig, calc_sub_ax = plt.subplots(figsize=(8,5))\n",
    "        calend_fig, calend_ax = plt.subplots(figsize=(8,5))\n",
    "        wiki_fig, wiki_ax = plt.subplots(figsize=(8,5))\n",
    "        joint_fig, joint_ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "        # Give title to each plot\n",
    "        calc_ax.set_title(\"Calculator augmented data\")\n",
    "        calend_ax.set_title(\"Calendar augmented data\")\n",
    "        wiki_ax.set_title(\"Wikisearch augmented data\")\n",
    "\n",
    "\n",
    "        #You pass the wanted axis to the ax argument\n",
    "        # df.plot(kind='scatter', x='x', y='y',title=\"Nice title\", grid=True,fontsize=10, ax=ax) \n",
    "\n",
    "        # Plot a scatter plot for each tool, where the x axis is the data perplexity and the y axis is the loss_improvement.\n",
    "        # Modify size of the scatter dots and colour and shape\n",
    "        calendar_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=joint_ax, s=2, c=\"relevance\", label=\"Calendar\", colormap=\"cool\", marker=\"x\")\n",
    "        wikisearch_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=joint_ax, s=2, c=\"relevance\", label=\"Wikisearch\", colormap=\"cool\", marker=\"o\")\n",
    "        calc_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=joint_ax, s=2, label=\"Calculator\", c=\"relevance\", colormap=\"cool\", marker=\"*\")\n",
    "        # Legend\n",
    "        joint_ax.legend()\n",
    "        # title\n",
    "        joint_ax.set_title(\"Augmented data\")\n",
    "\n",
    "\n",
    "        # Corresponding values for the colormap\n",
    "        # Here, we generate values between 0 and 1 based on class_labels\n",
    "        normalized_class_values = np.linspace(0, 1, len(CALC_SUBTYPES))\n",
    "        colormap_name = 'tab10'\n",
    "        color_map = plt.colormaps[colormap_name]\n",
    "\n",
    "        # Generate a color for each class based on the colormap\n",
    "        class_colors = color_map(normalized_class_values)\n",
    "\n",
    "        # Lines of filtering criteria\n",
    "        x_line = np.linspace(0, 350, 100)\n",
    "        calc_line = calc_m*x_line + calc_c\n",
    "        calend_line = calend_m*x_line + calend_c\n",
    "        wiki_line = wiki_m*x_line + wiki_c\n",
    "        # The calculator scatter plot should have different ops_labels with different colours:\n",
    "        for i, label in enumerate(CALC_SUBTYPES):\n",
    "            calc_df[calc_df[\"op_label\"] == label].plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=calc_sub_ax, s=4, label=label, color=class_colors[i])\n",
    "        calendar_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=calend_ax, s=10, c=\"relevance\", colormap=\"cool\",)\n",
    "        wikisearch_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=wiki_ax, s=10, c=\"relevance\", colormap=\"cool\",)\n",
    "        calc_df.plot.scatter(x=\"perplexity\", y=\"loss_improvement\", ax=calc_ax, s=10, c=\"relevance\", colormap=\"cool\",)\n",
    "        # Set line width\n",
    "        calc_sub_ax.plot(x_line, calc_line, color=class_colors[2], label=\"Filtering criteria\", linewidth=2)\n",
    "        calc_sub_ax.legend()\n",
    "        calend_ax.plot(x_line, calend_line, color=class_colors[2], label=\"Filtering criteria\", linewidth=2)\n",
    "        calend_ax.plot(x_line, calend_line+calend_bounds[0], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "        calend_ax.plot(x_line, calend_line-calend_bounds[1], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "        wiki_ax.plot(x_line, wiki_line, color=class_colors[2], label=\"Filtering criteria\", linewidth=2)\n",
    "        wiki_ax.plot(x_line, wiki_line+wiki_bounds[0], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "        wiki_ax.plot(x_line, wiki_line-wiki_bounds[1], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "        calc_ax.plot(x_line, calc_line, color=class_colors[2], label=\"Filtering criteria\", linewidth=2)\n",
    "        calc_ax.plot(x_line, calc_line+calc_bounds[0], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "        calc_ax.plot(x_line, calc_line-calc_bounds[1], color=class_colors[2], label=\"Filtering criteria\", linewidth=2, linestyle=\"--\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MAIIIIIIIIIIN\")\n",
    "    relevance_score(\"calculator subtype\", plots=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance score stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    25855.000000\n",
      "mean        -0.897221\n",
      "std          0.350527\n",
      "min         -1.495099\n",
      "25%         -1.124908\n",
      "50%         -0.943493\n",
      "75%         -0.735932\n",
      "max          2.954931\n",
      "Name: relevance, dtype: float64\n",
      "Calculator\n",
      "count    5880.000000\n",
      "mean       -0.945068\n",
      "std         0.388455\n",
      "min        -1.466302\n",
      "25%        -1.213272\n",
      "50%        -1.031171\n",
      "75%        -0.790287\n",
      "max         2.626328\n",
      "Name: relevance, dtype: float64\n",
      "\n",
      "WikiSearch\n",
      "count    10290.000000\n",
      "mean        -0.773997\n",
      "std          0.312015\n",
      "min         -1.174287\n",
      "25%         -0.968750\n",
      "50%         -0.838849\n",
      "75%         -0.661947\n",
      "max          2.954931\n",
      "Name: relevance, dtype: float64\n",
      "\n",
      "Calendar\n",
      "count    9685.000000\n",
      "mean       -0.999094\n",
      "std         0.324171\n",
      "min        -1.495099\n",
      "25%        -1.235086\n",
      "50%        -1.064829\n",
      "75%        -0.836967\n",
      "max         2.084497\n",
      "Name: relevance, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def relevance_score_stats(input):\n",
    "    input_dir =  construction_dir(input)\n",
    "\n",
    "    # Load the data\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    assert len(files) == 1\n",
    "    data = pd.read_csv(os.path.join(input_dir, files[0]))\n",
    "\n",
    "    # Get the stats\n",
    "    print(data['relevance'].describe())\n",
    "    for tool in TOOL_NAMES:\n",
    "        print(tool)\n",
    "        print(data[data.tool_name == tool]['relevance'].describe())\n",
    "        print()\n",
    "\n",
    "relevance_score_stats(\"relevance score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicity Rankings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicity_rankings(input, metric = \"relevance\"):\n",
    "\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"duplicity rankings\")\n",
    "\n",
    "    print(f\"Starting duplicity rankings for {input_dir} with metric {metric} to {output_dir}\")\n",
    "\n",
    "    tool_names = [\"Calculator\", \"Calendar\", \"WikiSearch\"]\n",
    "\n",
    "    if not os.path.exists(os.path.join(output_dir, \"stats\")):\n",
    "        os.mkdir(os.path.join(output_dir, \"stats\"))\n",
    "\n",
    "    files = os.listdir(input_dir)\n",
    "    assert len(files) == 1\n",
    "    df = pd.read_csv(os.path.join(input_dir, files[0]))\n",
    "\n",
    "    global_duplicity = {}\n",
    "    tool_specific_duplicity = {\n",
    "        tool: {} for tool in tool_names\n",
    "    }\n",
    "    # Get unique types of op_label and add them to tool_specific_duplicity\n",
    "    for subset in df.op_label.unique():\n",
    "        tool_specific_duplicity[subset] = {}\n",
    "        if subset not in CALC_SUBTYPES:\n",
    "            print(f\"Warning: {subset} not in CALC_SUBTYPES\")\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        tool = row.tool_name\n",
    "        text = row.text\n",
    "        score = row[metric]\n",
    "        subset = row.op_label\n",
    "        \n",
    "        try:\n",
    "            tool_specific_duplicity[tool][text] = tool_specific_duplicity[tool].get(text, []) + [score]\n",
    "            tool_specific_duplicity[subset][text] = tool_specific_duplicity[subset].get(text, []) + [score]\n",
    "            global_duplicity[text] = global_duplicity.get(text, []) + [score]\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError: {e}\")\n",
    "            print(f\"Row: {row}\")\n",
    "            print(f\"Iteration: {i}\")\n",
    "            raise e\n",
    "        \n",
    "    # Save the duplicity count in a json file\n",
    "    for tool in tool_names:\n",
    "        with open(f'{output_dir}/stats/duplicity_improvs_{tool}.json', 'w') as f:\n",
    "            json.dump(tool_specific_duplicity[tool], f)\n",
    "\n",
    "    # Save the duplicity count in a json file\n",
    "    with open(f'{output_dir}/stats/duplicity_count_global_{version_name}.json', 'w') as f:\n",
    "        json.dump(global_duplicity, f)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        text = row.text\n",
    "        subset = row.op_label\n",
    "        score = row[metric]\n",
    "        df.at[i, \"duplicity_count_global\"] = len(global_duplicity[text])\n",
    "        df.at[i, \"duplicity_ranking_global\"] = sorted(global_duplicity[text], reverse= True).index(score)\n",
    "        df.at[i, \"duplicity_ranking_subset\"] = sorted(tool_specific_duplicity[subset][text], reverse= True).index(score)\n",
    "\n",
    "        # ranking value is the index of the loss improvement in the sorted list of loss improvements\n",
    "        duplicity_ranking_tool = {}\n",
    "        duplicity_count_tool = {}\n",
    "        duplicity_ranking_subset = {}\n",
    "        for tool in tool_names:\n",
    "            count = 0\n",
    "            rank = 10000\n",
    "            try:\n",
    "                count = len(tool_specific_duplicity[tool][text])\n",
    "                rank = sorted(tool_specific_duplicity[tool][text], reverse= True).index(score)\n",
    "            except (ValueError, KeyError):\n",
    "                count = 0\n",
    "                rank = -1\n",
    "            duplicity_count_tool[tool] = count\n",
    "            duplicity_ranking_tool[tool] = rank\n",
    "            duplicity_ranking_subset[subset] = rank\n",
    "        \n",
    "        df.at[i, \"duplicity_ranking_stats\"] = str(duplicity_ranking_tool)\n",
    "        df.at[i, \"duplicity_count_stats\"] = str(duplicity_count_tool)\n",
    "        df.at[i, \"duplicity_ranking_tool\"] = duplicity_ranking_tool[row.tool_name]\n",
    "        df.at[i, \"duplicity_count_tool\"] = duplicity_count_tool[row.tool_name]\n",
    "\n",
    "    df.to_csv(os.path.join(output_dir, files[0]), index = False)\n",
    "\n",
    "\n",
    "#duplicity_rankings(\"relevance score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checker. Checks if any text is used in two tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multi_tool_duplicity(input):\n",
    "    input_dir = construction_dir(input)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "    print(files)\n",
    "\n",
    "    df = pd.read_csv(os.path.join(input_dir, files[0]))\n",
    "\n",
    "    # find rows where duplicity_count_tool != duplicity_count_global AND duplicity_ranking_global == 0\n",
    "    df = df[(df[\"duplicity_count_tool\"] != df[\"duplicity_count_global\"]) & (df[\"duplicity_ranking_global\"] == 0)]\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"No duplicity found. CHECK PASSED\")\n",
    "    else:\n",
    "        print(\"Duplicity found. CHECK FAILED:\")\n",
    "        print(f\"Length of df: {len(df)}\")\n",
    "\n",
    "        for i, row in df.head(20).iterrows():\n",
    "            print(row.API_call_response_text)\n",
    "            print(row.duplicity_count_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate training data (subset dataset)\n",
    "This script creates a training dataset file to feed the train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 3018 rows with an op_label that is not in the permitted_op_labels list\n",
      "Dropping 23276 rows with a tool ranking higher than 1 where tool_name != Calculator\n",
      "Leaving 2421 calc examples\n",
      "Final set has 7263 rows\n",
      "There are 2285 rows with duplicity_ranking_tool == 1\n",
      "       loss_improvement   perplexity    relevance  duplicity_ranking_tool  \\\n",
      "count       7263.000000  7263.000000  7263.000000             7263.000000   \n",
      "mean           1.284702   263.968278    -0.886763                0.314608   \n",
      "std            0.860120    56.877593     0.363300                0.464392   \n",
      "min            0.500078    11.900000    -1.495099                0.000000   \n",
      "25%            0.784509   233.900000    -1.125895                0.000000   \n",
      "50%            1.038763   276.200000    -0.940349                0.000000   \n",
      "75%            1.495171   308.050000    -0.723915                1.000000   \n",
      "max           12.549429   339.900000     2.599937                1.000000   \n",
      "\n",
      "       duplicity_ranking_subset  duplicity_ranking_global  \n",
      "count               7263.000000               7263.000000  \n",
      "mean                   0.249759                  0.314608  \n",
      "std                    0.432903                  0.464392  \n",
      "min                    0.000000                  0.000000  \n",
      "25%                    0.000000                  0.000000  \n",
      "50%                    0.000000                  0.000000  \n",
      "75%                    0.000000                  1.000000  \n",
      "max                    1.000000                  1.000000  \n",
      "\n",
      "\n",
      "Tool: Calculator\n",
      "       loss_improvement   perplexity    relevance  duplicity_ranking_tool  \\\n",
      "count       2421.000000  2421.000000  2421.000000             2421.000000   \n",
      "mean           0.917884   249.248162    -0.917462                0.334159   \n",
      "std            0.472702    67.276634     0.407148                0.471793   \n",
      "min            0.500078    11.900000    -1.455741                0.000000   \n",
      "25%            0.608641   206.500000    -1.198891                0.000000   \n",
      "50%            0.761938   261.000000    -1.006867                0.000000   \n",
      "75%            1.064862   304.800000    -0.757147                1.000000   \n",
      "max            5.541330   339.800000     2.599937                1.000000   \n",
      "\n",
      "       duplicity_ranking_subset  duplicity_ranking_global  \n",
      "count               2421.000000               2421.000000  \n",
      "mean                   0.139612                  0.334159  \n",
      "std                    0.346655                  0.471793  \n",
      "min                    0.000000                  0.000000  \n",
      "25%                    0.000000                  0.000000  \n",
      "50%                    0.000000                  0.000000  \n",
      "75%                    0.000000                  1.000000  \n",
      "max                    1.000000                  1.000000  \n",
      "\n",
      "Tool: WikiSearch\n",
      "       loss_improvement   perplexity    relevance  duplicity_ranking_tool  \\\n",
      "count       2421.000000  2421.000000  2421.000000             2421.000000   \n",
      "mean           1.573059   271.509831    -0.754221                0.375052   \n",
      "std            1.117394    50.962248     0.312718                0.484236   \n",
      "min            0.700134    23.600000    -1.164655                0.000000   \n",
      "25%            0.929092   244.500000    -0.956412                0.000000   \n",
      "50%            1.245483   280.200000    -0.820211                0.000000   \n",
      "75%            1.810525   311.900000    -0.639532                1.000000   \n",
      "max           12.549429   339.900000     1.680142                1.000000   \n",
      "\n",
      "       duplicity_ranking_subset  duplicity_ranking_global  \n",
      "count               2421.000000               2421.000000  \n",
      "mean                   0.375052                  0.375052  \n",
      "std                    0.484236                  0.484236  \n",
      "min                    0.000000                  0.000000  \n",
      "25%                    0.000000                  0.000000  \n",
      "50%                    0.000000                  0.000000  \n",
      "75%                    1.000000                  1.000000  \n",
      "max                    1.000000                  1.000000  \n",
      "\n",
      "Tool: Calendar\n",
      "       loss_improvement   perplexity    relevance  duplicity_ranking_tool  \\\n",
      "count       2421.000000  2421.000000  2421.000000             2421.000000   \n",
      "mean           1.363164   271.146840    -0.988607                0.234614   \n",
      "std            0.723920    47.532475     0.321890                0.423845   \n",
      "min            0.700516    16.600000    -1.495099                0.000000   \n",
      "25%            0.871899   243.400000    -1.221445                0.000000   \n",
      "50%            1.119691   281.500000    -1.048922                0.000000   \n",
      "75%            1.597549   308.500000    -0.833521                0.000000   \n",
      "max            6.614597   339.700000     0.854762                1.000000   \n",
      "\n",
      "       duplicity_ranking_subset  duplicity_ranking_global  \n",
      "count               2421.000000               2421.000000  \n",
      "mean                   0.234614                  0.234614  \n",
      "std                    0.423845                  0.423845  \n",
      "min                    0.000000                  0.000000  \n",
      "25%                    0.000000                  0.000000  \n",
      "50%                    0.000000                  0.000000  \n",
      "75%                    0.000000                  0.000000  \n",
      "max                    1.000000                  1.000000  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subset_data(input, p_displaced = 0.0):\n",
    "    import random\n",
    "    from beartype import beartype\n",
    "    import torch\n",
    "    import csv\n",
    "    import ast\n",
    "    random.seed(42)\n",
    "\n",
    "    input_dir = construction_dir(input)\n",
    "    output_dir = construction_dir(\"curated\")\n",
    "\n",
    "    file_list = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "    assert len(file_list) == 1, \"There should only be one csv file in the input directory\"\n",
    "\n",
    "    df = pd.read_csv(os.path.join(input_dir,file_list[0]))\n",
    "    permitted_op_labels = [\"multiply\",\"divide\",\"mult_divide\", \"add\", \"subtract\", \"add_subtract\", \"mix\"]\n",
    "\n",
    "    # Remove from the df all rows that have an op_label that is not in the permitted_op_labels list:\n",
    "    indices = (df.tool_name != \"Calculator\") | (df[\"op_label\"].isin(permitted_op_labels))\n",
    "    print(f\"Dropping {sum(~indices)} rows with an op_label that is not in the permitted_op_labels list\")\n",
    "    df = df[indices]\n",
    "    \n",
    "    # Remove from the df rows such that: tool_name != \"Calculator\" and a tool ranking higher than 2:\n",
    "    # Leaving calc check out as there is no mult_tool_duplicity\n",
    "    indices_rm = df[\"duplicity_ranking_tool\"] >= 2 # & df[\"tool_name\"] != \"Calculator\" \n",
    "    print(f\"Dropping {indices_rm.shape[0]} rows with a tool ranking higher than 1 where tool_name != Calculator\")\n",
    "    df = df[~indices_rm]\n",
    "\n",
    "    calc_count = sum(indices & (df.tool_name == \"Calculator\"))\n",
    "    print(f\"Leaving {calc_count} calc examples\")\n",
    "\n",
    "    calc_df = df[df[\"tool_name\"] == \"Calculator\"].sort_values(by=[\"relevance\"], ascending=True)\n",
    "    calendar_df = df[df[\"tool_name\"] == \"Calendar\"][0:len(calc_df*3)].sort_values(by=[\"relevance\"], ascending=True)\n",
    "    wiki_df = df[df[\"tool_name\"] == \"WikiSearch\"][0:len(calc_df*10)].sort_values(by=[\"relevance\"], ascending=True)\n",
    "    \n",
    "    # Shuffle a list of indices of length len(df):\n",
    "    indices = list(range(len(df)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Concat the dfs:\n",
    "    df[indices[:len(calc_df)]] = calc_df\n",
    "    df[indices[len(calc_df):len(calc_df)+len(calendar_df)]] = calendar_df\n",
    "    df[indices[len(calc_df)+len(calendar_df):len(calc_df)+len(calendar_df)+len(wiki_df)]] = wiki_df\n",
    "\n",
    "    # Sort df by decreasing relevance:\n",
    "    # df = df.sort_values(by=[\"relevance\"], ascending=True)\n",
    "\n",
    "    # Sample 20% of the indices:\n",
    "    indices = random.sample(range(df.shape[0]), int(df.shape[0]*p_displaced))\n",
    "    shuffled_indices = random.sample(indices, len(indices))\n",
    "    # Insert shuffled rows into the indices position:\n",
    "    df.iloc[indices] = df.iloc[shuffled_indices]\n",
    "\n",
    "    # Save the df to a csv file:\n",
    "    # The csv file should contain the columns: text, token_type, tool_name, calc_subtype\n",
    "    df[[\"text\", \"API_call_response_text\", \"tokenized_text\", \"token_type\", \"tool_name\", \"op_label\", \"relevance\", \"perplexity\", \"loss_improvement\"]].to_csv(os.path.join(output_dir, \"train_short.csv\"), index=False)\n",
    "    # Now we save a file with just the texts:\n",
    "    df[[\"text\", \"tool_name\"]].to_csv(os.path.join(output_dir, \"train_short_texts.csv\"), index=False)\n",
    "\n",
    "    print(f\"Final set has {df.shape[0]} rows\")\n",
    "\n",
    "    print(f\"There are {df[df.duplicity_ranking_tool == 1].shape[0]} rows with duplicity_ranking_tool == 1\")\n",
    "\n",
    "\n",
    "    return df\n",
    "fields_to_analyze = [\"loss_improvement\", \"perplexity\", \"relevance\",\"duplicity_ranking_tool\", \"duplicity_ranking_subset\", \"duplicity_ranking_global\"]\n",
    "df = subset_data(\"duplicity rankings\")\n",
    "\n",
    "print(df[fields_to_analyze].describe())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "for tool in TOOL_NAMES:\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(df[df.tool_name == tool][fields_to_analyze].describe())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7263\n",
      "Index(['text', 'API_call_response_text', 'tokenized_text', 'token_type',\n",
      "       'tool_name', 'op_label'],\n",
      "      dtype='object')\n",
      "The product of Q5, Q22 and Q23 is the perfect square 2050 · 4633 · 226 = <TOOL>Calculator(4633*4633)→ 21464689.0</TOOL> 2146468900 = 463302 = (2 · 5 ·\n",
      "The product of Q5, Q22 and Q23 is the perfect square 2050 · 4633 · 226 = <TOOL>Calculator(2050*4633*226)→ 2146468900.0</TOOL> 2146468900 = 463302 = (2 · 5 ·\n",
      "d 00:05h Aug 13, 2018 6:45:35 pm - 0% 31 13 <TOOL>Calculator(31/13)→ 2.38</TOOL> 2.38 100% 33% RIDE WIT DA MOB 0\n",
      "Torque is basically proportional to current, so 550A/300A * 35 ft-lb = <TOOL>Calculator(550/300*35)→ 64.05</TOOL> 64 ft-lb.\n",
      " then divide by 2 (16 miles /2) / 60 minutes (16 miles/2)/ 1 minute <TOOL>Calculator(16/2)→ 8.0</TOOL> 8 miles/ 1 minute 1 minute/ 8 miles Thank you for the explanation.\n",
      "Keweenaw County, Michigan's gender ratio is higher than the Michigan State average of 97 men to 100 women (97:100) or <TOOL>Calculator(97/100)→ 0.97</TOOL> 0.97.\n",
      "Multiply 24 by five-ninths of 1% to get a <TOOL>Calculator(24*5*10/9)→ 133.2</TOOL> 13.3% reduction in benefits.\n",
      "Pursuant to article 56 of the Italian Constitution, the Chamber of Deputies has <TOOL>Calculator(56*2)→ 112.0</TOOL> 630 seats, of which 618 are elected from Italian constituencies, and 12 from Italian citizens living abroad.\n",
      "The changeover to the euro will be based on the exchange rate of the lat to the euro set by the Bank of Latvia (0.702804), whereby each lat is equal to  <TOOL>Calculator(1/0.702804)→ 1.42</TOOL>1.42 euro.\n",
      "The “EP” at the National Archives February 12, 2018 February 15, 2018 by jessiekratz, posted in - Civil War, Abraham Lincoln, preservation <TOOL>Calculator(12/255)→ 0.05</TOOL> On January 1, 1863, President Abraham Lincoln\n"
     ]
    }
   ],
   "source": [
    "input_dir = construction_dir(\"curated\")\n",
    "input_2 = construction_dir(\"duplicity rankings\")\n",
    "\n",
    "files = [f for f in os.listdir(input_dir ) if f.endswith(\".csv\")]\n",
    "files2 = [f for f in os.listdir(input_2 ) if f.endswith(\".csv\")]\n",
    "\n",
    "df = pd.read_csv(os.path.join(input_dir, files[0]))\n",
    "\n",
    "df2 = pd.read_csv(os.path.join(input_2, files2[0]))\n",
    "\n",
    "print(len(df))\n",
    "print(df.columns)\n",
    "\n",
    "train_rows = []\n",
    "\n",
    "for i, row in df[df.tool_name == \"Calculator\"].iterrows():\n",
    "    new_row = df2[df2[\"API_call_response_text\"] == row[\"API_call_response_text\"]]\n",
    "\n",
    "    train_rows.append(new_row)\n",
    "\n",
    "df3 = pd.concat(train_rows)\n",
    "print(len(df3))\n",
    "\n",
    "for i, row in df3.sort_values(by=\"relevance\", ascending=False).head(10).iterrows():\n",
    "    print(row.API_call_response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num_return_sequences  max_new_tokens  top_k\n",
      "0                      0              10     99\n",
      "1                      1              10     98\n",
      "2                      2              10     97\n",
      "3                      3              10     96\n",
      "4                      4              10     95\n",
      "5                      5              10     94\n",
      "6                      6              10     93\n",
      "7                      7              10     92\n",
      "8                      8              10     91\n",
      "9                      9              10     90\n",
      "10                    10              10     89\n",
      "11                    68              10     31\n",
      "12                    12              10     87\n",
      "13                    13              10     86\n",
      "14                    14              10     85\n",
      "15                    97              10      2\n",
      "16                    16              10     83\n",
      "17                    17              10     82\n",
      "18                    18              10     81\n",
      "19                    46              10     53\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Mock dataset to convert to pandas dataframe\n",
    "data = {\n",
    "    \"num_return_sequences\": list(range(100)),\n",
    "    \"max_new_tokens\": [10,]*100,\n",
    "    \"top_k\": list(reversed(range(100))),\n",
    "}\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Sample 20% of the indices:\n",
    "indices = random.sample(range(df.shape[0]), int(df.shape[0]*0.15))\n",
    "shuffled_indices = random.sample(indices, len(indices))\n",
    "# Insert shuffled rows into the indices position:\n",
    "df.iloc[indices] = df.iloc[shuffled_indices]\n",
    "\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substituting tokens in files in directory:  /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/origin/GPTJ_shiny_new\n",
      "Processing:  Calculator_2.csv\n",
      "Processing:  Calculator_1.csv\n",
      "Processing:  Calculator_0.csv\n",
      "Processing:  WikiSearch_0.csv\n",
      "Processing:  WikiSearch_1.csv\n",
      "Processing:  WikiSearch_2.csv\n",
      "Processing:  Calendar_6.csv\n",
      "Processing:  Calendar_1.csv\n",
      "Processing:  Calendar_8.csv\n",
      "Processing:  Calendar_0.csv\n",
      "Processing:  Calendar_7.csv\n",
      "Processing:  Calendar_4.csv\n",
      "Processing:  Calendar_3.csv\n",
      "Processing:  Calendar_2.csv\n",
      "Processing:  Calendar_5.csv\n",
      "Removing long white spaces from /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/tool_token_substitution/GPTJ_shiny_new and saving to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/white_space_removal/GPTJ_shiny_new\n",
      "Processing Calculator_1.csv\n",
      "Processing WikiSearch_2.csv\n",
      "Processing Calendar_2.csv\n",
      "Processing Calendar_5.csv\n",
      "Processing Calendar_4.csv\n",
      "Processing Calendar_3.csv\n",
      "Processing Calculator_0.csv\n",
      "Processing WikiSearch_0.csv\n",
      "Processing Calendar_0.csv\n",
      "Processing Calendar_7.csv\n",
      "Processing Calculator_2.csv\n",
      "Processing Calendar_8.csv\n",
      "Processing Calendar_6.csv\n",
      "Processing WikiSearch_1.csv\n",
      "Processing Calendar_1.csv\n",
      "Token type masking /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/white_space_removal/GPTJ_shiny_new to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/token_type_masking/GPTJ_shiny_new\n",
      "Processing Calendar with 3 files\n",
      "Downloading and preparing dataset csv/GPTJ_shiny_new to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-a68e88b4610ff761/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1151.65it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 35.94it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-a68e88b4610ff761/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n",
      "Processing WikiSearch with 3 files\n",
      "Downloading and preparing dataset csv/GPTJ_shiny_new to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-17032c3810bf4d50/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1640.96it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 37.26it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-17032c3810bf4d50/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n",
      "Processing Calculator with 3 files\n",
      "Downloading and preparing dataset csv/GPTJ_shiny_new to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-6c4ae4d6f525f09f/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1596.01it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 40.70it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-6c4ae4d6f525f09f/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n",
      "Starting calculator subtype......\n",
      "['train.csv']\n",
      "Loading train.csv\n",
      "Downloading and preparing dataset csv/GPTJ_shiny_new to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-ef4e8e77050d060f/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2931.03it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 108.11it/s]\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/toolformer/cache/csv/GPTJ_shiny_new-ef4e8e77050d060f/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n",
      "Starting relevance score calculation...\n",
      "Len of calc_df: 6319, len of calendar_df: 9685, len of wikisearch_df: 10290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2429078/3256227915.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  calc_df.loc[:,\"relevance\"] = - np.sin(calc_theta) * calc_df.perplexity + np.cos(calc_theta) * (calc_df.loss_improvement  - calc_c)\n",
      "/tmp/ipykernel_2429078/3256227915.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  calendar_df.loc[:,\"relevance\"] = - np.sin(calend_theta) * calendar_df[\"perplexity\"] + np.cos(calend_theta) * (calendar_df[\"loss_improvement\"]  - calend_c)\n",
      "/tmp/ipykernel_2429078/3256227915.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikisearch_df.loc[:,\"relevance\"] = - np.sin(wiki_theta) * wikisearch_df[\"perplexity\"] + np.cos(wiki_theta) * (wikisearch_df[\"loss_improvement\"]  - wiki_c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26294.000000\n",
      "mean        -0.898189\n",
      "std          0.351025\n",
      "min         -1.495099\n",
      "25%         -1.126576\n",
      "50%         -0.945268\n",
      "75%         -0.736922\n",
      "max          2.954931\n",
      "Name: relevance, dtype: float64\n",
      "Calculator\n",
      "count    6319.000000\n",
      "mean       -0.945774\n",
      "std         0.387528\n",
      "min        -1.463070\n",
      "25%        -1.212637\n",
      "50%        -1.032465\n",
      "75%        -0.793384\n",
      "max         2.599937\n",
      "Name: relevance, dtype: float64\n",
      "\n",
      "WikiSearch\n",
      "count    10290.000000\n",
      "mean        -0.773997\n",
      "std          0.312015\n",
      "min         -1.174287\n",
      "25%         -0.968750\n",
      "50%         -0.838849\n",
      "75%         -0.661947\n",
      "max          2.954931\n",
      "Name: relevance, dtype: float64\n",
      "\n",
      "Calendar\n",
      "count    9685.000000\n",
      "mean       -0.999094\n",
      "std         0.324171\n",
      "min        -1.495099\n",
      "25%        -1.235086\n",
      "50%        -1.064829\n",
      "75%        -0.836967\n",
      "max         2.084497\n",
      "Name: relevance, dtype: float64\n",
      "\n",
      "Starting duplicity rankings for /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/relevance_score/GPTJ_shiny_new with metric relevance to /vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/duplicity_rankings/GPTJ_shiny_new\n",
      "Warning: NotApplicable not in CALC_SUBTYPES\n",
      "['train.csv']\n",
      "No duplicity found. CHECK PASSED\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'subset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m duplicity_rankings(\u001b[39m\"\u001b[39m\u001b[39mrelevance score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m check_multi_tool_duplicity(\u001b[39m\"\u001b[39m\u001b[39mduplicity rankings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m subset_data(\u001b[39m\"\u001b[39;49m\u001b[39mduplicity rankings\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36msubset_data\u001b[0;34m(input, p_displaced)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mast\u001b[39;00m\n\u001b[1;32m      8\u001b[0m input_dir \u001b[39m=\u001b[39m construction_dir(\u001b[39minput\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m output_dir \u001b[39m=\u001b[39m construction_dir(\u001b[39m\"\u001b[39;49m\u001b[39msubset\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m file_list \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(input_dir) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     12\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(file_list) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThere should only be one csv file in the input directory\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[18], line 33\u001b[0m, in \u001b[0;36mconstruction_dir\u001b[0;34m(part)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstruction_dir\u001b[39m(part):\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CONSTRUCTION_DIRS[part], MODEL_NAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m version_name)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subset'"
     ]
    }
   ],
   "source": [
    "tool_token_substitution(\"origin\")\n",
    "white_space_removal(\"tool token substitution\")\n",
    "token_type_masking(\"white space removal\")\n",
    "calculator_subtype(\"token type masking\")\n",
    "relevance_score(\"calculator subtype\")\n",
    "relevance_score_stats(\"relevance score\")\n",
    "duplicity_rankings(\"relevance score\")\n",
    "check_multi_tool_duplicity(\"duplicity rankings\")\n",
    "df = subset_data(\"duplicity rankings\")\n",
    "\n",
    "fields_to_analyze = [\"loss_improvement\", \"perplexity\", \"relevance\",\"duplicity_ranking_tool\", \"duplicity_ranking_subset\", \"duplicity_ranking_global\"]\n",
    "print(df[fields_to_analyze].describe())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "for tool in TOOL_NAMES:\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(df[df.tool_name == tool][fields_to_analyze].describe())\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  [2061, 345, 714, 466, 351, 257, 1597, 318, 923...   \n",
      "1  [1544, 373, 50400, 9771, 9239, 7, 1267, 39310,...   \n",
      "2  [464, 1074, 468, 4504, 284, 4505, 475, 612, 31...   \n",
      "3  [37844, 389, 24495, 319, 262, 50400, 9771, 923...   \n",
      "4  [1026, 973, 262, 14037, 284, 262, 4495, 284, 2...   \n",
      "\n",
      "                                          token_type   tool_name calc_subtype  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  WikiSearch          NaN   \n",
      "1  [0, 0, 1, 2, 2, 3, 5, 6, 7, 7, 7, 7, 7, 7, 7, ...    Calendar          NaN   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, ...  WikiSearch          NaN   \n",
      "3  [0, 0, 0, 0, 0, 1, 2, 2, 3, 5, 6, 7, 7, 7, 7, ...    Calendar          NaN   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, ...    Calendar          NaN   \n",
      "\n",
      "   data_id  \n",
      "0    19343  \n",
      "1    11057  \n",
      "2    18943  \n",
      "3    11238  \n",
      "4    10203  \n",
      "Columns in short_train_df: Index(['text', 'token_type', 'tool_name', 'calc_subtype', 'data_id'], dtype='object')\n",
      "Len of raw_texts: 3549\n",
      "Saved raw_texts to file: texts_used_train_resplandor_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Open file texts_used_train_resplandor.txt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "short_train_df = pd.read_csv(\"texts_used_train_resplandor.csv\")\n",
    "print(short_train_df.head())\n",
    "\n",
    "# Open training data at path: os.path.join(CONSTRUCTION_DIRS[\"calculator subtype\"][\"output\"], MODEL_NAME + \"_\" + version_name)\n",
    "train_data_dir = os.path.join(CONSTRUCTION_DIRS[\"calculator subtype\"][\"output\"], MODEL_NAME + \"_\" + version_name)\n",
    "files = [f for f in os.listdir(train_data_dir) if f.endswith(\".csv\")]\n",
    "train_df = pd.concat([pd.read_csv(os.path.join(train_data_dir, f)) for f in files])\n",
    "\n",
    "raw_texts = []\n",
    "\n",
    "# Print columns in short_train_df:\n",
    "print(f\"Columns in short_train_df: {short_train_df.columns}\")\n",
    "\n",
    "for i, row in short_train_df.iterrows():\n",
    "    raw_texts.append(train_df.iloc[row[\"data_id\"]][\"text\"])\n",
    "\n",
    "    # Assert that tokenized text in train_df is the same as the tokenized text in short_train_df\n",
    "    # assert tokenizer.encode(train_df.iloc[row[\"data_id\"]][\"API_call_response_text\"]) == row[\"text\"], f\"Tokenized text in train_df is not the same as the tokenized text in short_train_df: {train_df.iloc[row['data_id']]['API_call_response_text']} != {tokenizer.decode(ast.literal_eval(row['text']))}\"\n",
    "\n",
    "\n",
    "print(f\"Len of raw_texts: {len(raw_texts)}\")\n",
    "\n",
    "# Save raw_texts to csv file with the same name as the short_train_df file but adding _raw\n",
    "raw_texts_df = pd.DataFrame(raw_texts)\n",
    "raw_texts_df.to_csv(\"texts_used_train_resplandor_raw.csv\", index=False)\n",
    "print(f\"Saved raw_texts to file: texts_used_train_resplandor_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2\n",
      "2.8113050706566916\n",
      "1.5150422577922704\n"
     ]
    }
   ],
   "source": [
    "# Go through values of tool_specific_duplicity and find max min average and std\n",
    "from statistics import mean, stdev\n",
    "import numpy as np\n",
    "\n",
    "global_duplicity # Dictioray whose values we want to analyze\n",
    "\n",
    "# Get max, min, average, and std\n",
    "print(max(global_duplicity.values()))\n",
    "print(min(global_duplicity.values()))\n",
    "print(mean(global_duplicity.values()))\n",
    "print(stdev(global_duplicity.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'text', 'API_calls_text', 'API_call_response_text', 'position',\n",
      "       'loss_improvement', 'processed_arg', 'title', 'date_download', 'digest',\n",
      "       'length', 'nlines', 'source_domain', 'cc_segment', 'original_nlines',\n",
      "       'original_length', 'language', 'language_score', 'perplexity', 'bucket',\n",
      "       'tokenized_start_text', 'tool_name', 'tokenized_text', 'token_type',\n",
      "       'tokenized_end_text', 'start_token_type', 'end_token_type',\n",
      "       'start_method_A_train_mask', 'end_method_A_train_mask',\n",
      "       'duplicity_count_tool', 'duplicity_count_global',\n",
      "       'duplicity_ranking_tool', 'duplicity_ranking_global',\n",
      "       'duplicity_count_stats', 'duplicity_ranking_stats', 'op_label',\n",
      "       'ops_used', 'relevance', 'duplicity_ranking_subset'],\n",
      "      dtype='object')\n",
      "Even on a dreary winter day <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> in New Jersey.\n",
      "You will both appreciate having some alone time together after <TOOL>Calendar()→ Today is Saturday, August 30, 2014</TOOL> your first morning apart from each other.\n",
      "This book brings you very close to the soul of <TOOL>Calendar()→ Today is Thursday, February 15, 2018</TOOL> Paul.\n",
      "Our Master is calling us to <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> draw near to Him in faith.\n",
      "You will both appreciate having some alone time together after your <TOOL>Calendar()→ Today is Saturday, August 30, 2014</TOOL> first morning apart from each other.\n",
      "\"If you have any <TOOL>Calendar()→ Today is Tuesday, September 11, 2018</TOOL> communities that make you feel happy...you should go back to that,\" Santiago said.\n",
      "Most <TOOL>Calendar()→ Today is Saturday, July 21, 2007</TOOL> do not understand that classical electrodynamics is purely special relativistic!\n",
      "For one <TOOL>Calendar()→ Today is Friday, July 11, 2014</TOOL> thing, certain physicists are pursuing even superior heights of sureness in the standard model of particle physics; for another, the standard model isn't a comprehensive explanation of the way the subatomic realm actually operates\n",
      "It is not always easy to welcome a new <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> year.\n",
      "The <TOOL>Calendar()→ Today is Saturday, February 1, 2014</TOOL> famine following the feast.\n",
      "Q: During the course of a 20-minute highway drive it is not unusual for me to see four <TOOL>Calendar()→ Today is Sunday, March 25, 2018</TOOL> cars with a single headlight, and I’m being careful not to count motorcycles.\n",
      "This last <TOOL>Calendar()→ Today is Monday, October 25, 2010</TOOL> remark may cause some raising of eyebrows, but it seems to be warranted by the facts.\n",
      "I've done it for nearly <TOOL>Calendar()→ Today is Wednesday, March 11, 2009</TOOL> three hours now, and has written a lot on my novel.\n",
      "In that act, it moved a <TOOL>Calendar()→ Today is Monday, December 11, 2017</TOOL> boundary.\n",
      "You will need an electrician or qualified person to <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> perform this test.\n",
      "He pointed out that it’s <TOOL>Calendar()→ Today is Sunday, September 19, 2010</TOOL> like living on interest, rather than increasing one’s capital.\n",
      "I would like to <TOOL>Calendar()→ Today is Wednesday, August 18, 2010</TOOL> point out that SECRETS has received THREE favorable reviews.\n",
      "You will see how <TOOL>Calendar()→ Today is Wednesday, November 15, 2017</TOOL> to process data and make predictive models from it.\n",
      "Then came his moody, actorly turn in <TOOL>Calendar()→ Today is Friday, June 11, 2004</TOOL> \"A Man Apart,\" which nobody really wanted to see, including those who saw it.\n",
      "I don’t know if <TOOL>Calendar()→ Today is Saturday, February 1, 2014</TOOL> I am quietly blowing minds or if people are just blowing chunks.\n",
      "Ordinarily Blue Monday is <TOOL>Calendar()→ Today is Saturday, February 1, 2014</TOOL> the third Monday of January; this year it was decided that the 6th, the first Monday after the holiday, was the official date.\n",
      "However, Shann <TOOL>Calendar()→ Today is Tuesday, February 11, 2014</TOOL> holds the key that could either cause peace between the two nations or cause a bitter war.\n",
      "Ellen is always enthusiastic and funny, her partner, <TOOL>Calendar()→ Today is Thursday, May 29, 2008</TOOL> Delia Sherman, was there to answer questions about how they’ve worked together, and the setting was intimate.\n",
      "But it's <TOOL>Calendar()→ Today is Monday, July 11, 2011</TOOL> not every day that we're reminded to count our many blessings.\n",
      "If your neighbor's kid broke you car window, you will <TOOL>Calendar()→ Today is Wednesday, March 11, 2009</TOOL> get angry.\n",
      "if <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> some current passes through a person.\n",
      "God’s law <TOOL>Calendar()→ Today is Monday, December 11, 2017</TOOL> serves an evangelical and missionary purpose today as it did at the time of the children of Israel.\n",
      "So the <TOOL>Calendar()→ Today is Thursday, March 11, 2010</TOOL> virtual and the real are interwoven in new ways.\n",
      "I've done it for nearly three <TOOL>Calendar()→ Today is Wednesday, March 11, 2009</TOOL> hours now, and has written a lot on my novel.\n",
      "Ladies and gentlemen… here <TOOL>Calendar()→ Today is Saturday, October 16, 1999</TOOL> is Geezer Butler!\n",
      "50% off <TOOL>Calendar()→ Today is Wednesday, November 15, 2017</TOOL> Kafka Streams in Action 50% off Manning’s eBook by Bill Bejeck.\n",
      "Original drummer <TOOL>Calendar()→ Today is Saturday, October 16, 1999</TOOL> Bill Ward had departed and skin pounder Vinny Appice took the throne behind the band, bringing his signature heavy style to the band.\n",
      "Enjoy <TOOL>Calendar()→ Today is Monday, February 11, 2013</TOOL> your moment in the sun.\n",
      "In November 2013, <TOOL>Calendar()→ Today is Friday, August 11, 2017</TOOL> a review of 26 studies found that otherwise healthy men and women didn't have a lesser risk of cancer or heart diseases after taking a daily multivitamin.\n",
      "The American Lawyer has also honored <TOOL>Calendar()→ Today is Thursday, April 5, 2018</TOOL> Josh twice as Litigator of the Year.\n",
      "I believe that wicketkeepers are <TOOL>Calendar()→ Today is Sunday, May 20, 2018</TOOL> very correct as vice-captain, but Not for captaincy.\n",
      "God tells Mack <TOOL>Calendar()→ Today is Sunday, January 11, 2015</TOOL> that relationship is not about expectation, but rather about expectancy.\n",
      "Amanda Palmer, frontwoman for the Dresden Dolls, will be coming to town August 9 as a solo act for a show at the <TOOL>Calendar()→ Today is Wednesday, June 11, 2008</TOOL> teeny-tiny Rivoli.\n",
      "Aron Finch will support Tim as the vice-captain for this five-match <TOOL>Calendar()→ Today is Sunday, May 20, 2018</TOOL> ODI series.\n",
      "Each of the two charges involved is <TOOL>Calendar()→ Today is Saturday, July 21, 2007</TOOL> infinite, and each has infinite energy!\n",
      "As an adult, I have even bought back <TOOL>Calendar()→ Today is Thursday, June 9, 2011</TOOL> some of the comics that I used to own as a kid.\n",
      "After a <TOOL>Calendar()→ Today is Sunday, May 20, 2018</TOOL> one-year ban on Steve Smith and David Warner in the ball tampering case, Cricket Australia (CA) has made Penn the captain of the team for England tour.\n",
      "She’s <TOOL>Calendar()→ Today is Saturday, November 18, 2017</TOOL> so clever.\n",
      "State law and court cases hold that Tennessee is <TOOL>Calendar()→ Today is Monday, December 11, 2017</TOOL> not a common law state in marriage, and that only unions created under the statute are recognized at law and legally enforceable.\n",
      "Axing <TOOL>Calendar()→ Today is Friday, August 17, 2018</TOOL> wildfire and algae research during wildfire and algae emergencies is unpopular, and election-seekers are hearing as much.\n",
      "If you listen to <TOOL>Calendar()→ Today is Wednesday, March 11, 2009</TOOL> a classical music, your right brain will take the lead.\n",
      "They showing an understanding of the <TOOL>Calendar()→ Today is Sunday, March 14, 2010</TOOL> tabloid.\n",
      "Mike and I ran out <TOOL>Calendar()→ Today is Wednesday, July 11, 2012</TOOL>, bought a juicer, loaded up on fruits and vegetables, and decided to skip the “last meal” (pizza, tacos, ice cream, etc).\n",
      "To join the RCMP, graduates must <TOOL>Calendar()→ Today is Friday, June 15, 2018</TOOL> pass a medical examination, obtain an RCMP Security Clearance and pass an interview.\n",
      "They’re not on the bill next Friday night in Toronto but will be here on their own for a show at Sneaky Dee’s on <TOOL>Calendar()→ Today is Wednesday, June 11, 2008</TOOL> July 22.\n"
     ]
    }
   ],
   "source": [
    "# Open train file and study lower relevance data points:\n",
    "\n",
    "dir_file = \"/vol/bitbucket/jg2619/augmenting_llms/augmented_data_pipeline/data/train/construction/duplicity_rankings/GPTJ_shiny_new/train.csv\"\n",
    "\n",
    "df = pd.read_csv(dir_file)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "for _,row in df.sort_values(by=\"relevance\", ascending=True).head(50).iterrows():\n",
    "    print(row.API_call_response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldtoolvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
